{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "32yCsRUo8H33"
      },
      "source": [
        "# 2024 COMP90042 Project\n",
        "*Make sure you change the file name with your group id.*"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XCybYoGz8YWQ"
      },
      "source": [
        "# Readme\n",
        "This is just a baseline model for evidence retrieval. You may have no need to run it as it is just a baseline that we used.\n",
        "\n",
        "We uploaded this just because we still spent a lot of time on it actually so we hope this can be seen as our efforts for this project, too."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6po98qVA8bJD"
      },
      "source": [
        "# 1.DataSet Processing\n",
        "(You can add as many code blocks and text blocks as you need. However, YOU SHOULD NOT MODIFY the section title)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mFYaQndfIA3s"
      },
      "source": [
        "1.Clone the repository to get the data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qvff21Hv8zjk",
        "outputId": "7f22c4d7-954d-48c2-decd-e49ad34c2164"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "32768"
            ]
          },
          "metadata": {},
          "execution_count": 1
        }
      ],
      "source": [
        "import os\n",
        "\n",
        "# the repository link:\n",
        "repository_url = 'https://github.com/drcarenhan/COMP90042_2024.git'\n",
        "\n",
        "# clone the repository\n",
        "os.system(f'git clone {repository_url}')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bs1iyaPdIFwB"
      },
      "source": [
        "We still need to download the evidence data from the google drive as it is not in the repository."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HsEuIkGtJvT2",
        "outputId": "6a12db5f-7340-45d7-c5fc-0b3f1d763c97"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/gdown/__main__.py:132: FutureWarning: Option `--id` was deprecated in version 4.3.1 and will be removed in 5.0. You don't need to pass it anymore to use a file ID.\n",
            "  warnings.warn(\n",
            "Downloading...\n",
            "From (original): https://drive.google.com/uc?id=1JlUzRufknsHzKzvrEjgw8D3n_IRpjzo6\n",
            "From (redirected): https://drive.google.com/uc?id=1JlUzRufknsHzKzvrEjgw8D3n_IRpjzo6&confirm=t&uuid=21dad9c4-9125-438f-b54d-23b0edfce037\n",
            "To: /content/COMP90042_2024/data/evidence.json\n",
            "100% 174M/174M [00:01<00:00, 87.8MB/s]\n"
          ]
        }
      ],
      "source": [
        "save_path = '/content/COMP90042_2024/data'\n",
        "os.makedirs(save_path, exist_ok=True)\n",
        "\n",
        "output_file_path = os.path.join(save_path, 'evidence.json')\n",
        "\n",
        "!gdown --id '1JlUzRufknsHzKzvrEjgw8D3n_IRpjzo6' -O {output_file_path}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vpNnkshBXLzu"
      },
      "source": [
        "Read all the related data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "X7hRqqbPXRPO"
      },
      "outputs": [],
      "source": [
        "import json\n",
        "\n",
        "with open(save_path+'/train-claims.json', 'r') as file:\n",
        "    train_claims_data = json.load(file)\n",
        "\n",
        "with open(save_path+'/evidence.json', 'r') as file:\n",
        "    evidence_data = json.load(file)\n",
        "\n",
        "with open(save_path+'/dev-claims.json', 'r') as file:\n",
        "    dev_claims_data = json.load(file)\n",
        "\n",
        "with open(save_path+'/dev-claims-baseline.json', 'r') as file:\n",
        "    dev_claims_baseline_data = json.load(file)\n",
        "\n",
        "with open(save_path+'/test-claims-unlabelled.json', 'r') as file:\n",
        "    test_claims_unlabelled_data = json.load(file)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r1tNWH2jzpvg"
      },
      "source": [
        "Making the traning set pairs (claim,evidence,label)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "ruF3wJzvg4gB"
      },
      "outputs": [],
      "source": [
        "# Extract all evidence IDs used in train_claims_data\n",
        "train_evidence_ids = set()\n",
        "for claim in train_claims_data.values():\n",
        "    train_evidence_ids.update(claim['evidences'])\n",
        "\n",
        "# Create a subset of evidence_data containing only those evidences referenced in train_claims_data\n",
        "train_evidence_subset = {eid: evidence_data[eid] for eid in train_evidence_ids if eid in evidence_data}\n",
        "\n",
        "# Extract all evidence IDs used in train_claims_data\n",
        "dev_evidence_ids = set()\n",
        "for claim in dev_claims_data.values():\n",
        "    dev_evidence_ids.update(claim['evidences'])\n",
        "\n",
        "# Create a subset of evidence_data containing only those evidences referenced in train_claims_data\n",
        "dev_evidence_subset = {eid: evidence_data[eid] for eid in dev_evidence_ids if eid in evidence_data}\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TR7E0TKJp1pV"
      },
      "source": [
        "### Preprocessing"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TrRUYQUIkqos"
      },
      "source": [
        "prepare the training dataset that claim and evidence are stored separately"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "vrAC0jY9pwPN"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "\n",
        "positive_train_pairs =  []\n",
        "for claim_id, claim_infor in train_claims_data.items():\n",
        "    for evidence_id in claim_infor['evidences']:\n",
        "        positive_train_pairs.append((claim_id, evidence_id))\n",
        "\n",
        "positive_train_text_pairs = []\n",
        "for claim_id, evidence_id in positive_train_pairs:\n",
        "    positive_train_text_pairs.append((train_claims_data[claim_id]['claim_text'], evidence_data[evidence_id]))\n",
        "\n",
        "positive_dev_pairs =  []\n",
        "for claim_id, claim_infor in dev_claims_data.items():\n",
        "    for evidence_id in claim_infor['evidences']:\n",
        "        positive_dev_pairs.append((claim_id, evidence_id))\n",
        "\n",
        "positive_dev_text_pairs = []\n",
        "for claim_id, evidence_id in positive_dev_pairs:\n",
        "    positive_dev_text_pairs.append((dev_claims_data[claim_id]['claim_text'], evidence_data[evidence_id]))\n",
        "# Get the question and answer list\n",
        "train_claim_list = [pair[0] for pair in positive_train_text_pairs]\n",
        "train_evidence_list = [pair[1] for pair in positive_train_text_pairs]\n",
        "\n",
        "dev_claim_list = [pair[0] for pair in positive_dev_text_pairs]\n",
        "dev_evidence_list = [pair[1] for pair in positive_dev_text_pairs]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VJlNXk-wsOJb",
        "outputId": "c34d5e07-bcd9-490d-f734-b73c2bd3ccd6"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "4122"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ],
      "source": [
        "n_data = len(positive_train_pairs)\n",
        "n_data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jp9lPdQdqb4D",
        "outputId": "5babeb3c-f6cb-4abe-d262-77d5009e0ed7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n",
            "100%|██████████| 4122/4122 [00:03<00:00, 1319.85it/s]\n",
            "100%|██████████| 4122/4122 [00:03<00:00, 1175.12it/s]\n",
            "100%|██████████| 491/491 [00:00<00:00, 1171.91it/s]\n",
            "100%|██████████| 491/491 [00:00<00:00, 911.72it/s]\n"
          ]
        }
      ],
      "source": [
        "import re\n",
        "import nltk\n",
        "nltk.download('punkt')\n",
        "nltk.download('stopwords')\n",
        "nltk.download('wordnet')\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.tokenize import word_tokenize\n",
        "from tqdm import tqdm\n",
        "from nltk.stem import *\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "\n",
        "# Have a look at some contractions of words! Contractions include punctuation - how would you handle them? There are many edge cases. i.e. can't, she'll\n",
        "contraction_dict = {\"ain't\": \"is not\", \"aren't\": \"are not\",\"can't\": \"cannot\", \"'cause\": \"because\", \"could've\": \"could have\",\n",
        "                    \"couldn't\": \"could not\", \"didn't\": \"did not\",  \"doesn't\": \"does not\", \"don't\": \"do not\", \"hadn't\": \"had not\",\n",
        "                    \"hasn't\": \"has not\", \"haven't\": \"have not\", \"he'd\": \"he would\",\"he'll\": \"he will\", \"he's\": \"he is\", \"how'd\": \"how did\",\n",
        "                    \"how'd'y\": \"how do you\", \"how'll\": \"how will\", \"how's\": \"how is\",  \"I'd\": \"I would\", \"I'd've\": \"I would have\",\n",
        "                    \"I'll\": \"I will\", \"I'll've\": \"I will have\",\"I'm\": \"I am\", \"I've\": \"I have\", \"i'd\": \"i would\", \"i'd've\": \"i would have\",\n",
        "                    \"i'll\": \"i will\",  \"i'll've\": \"i will have\",\"i'm\": \"i am\", \"i've\": \"i have\", \"isn't\": \"is not\", \"it'd\": \"it would\",\n",
        "                    \"it'd've\": \"it would have\", \"it'll\": \"it will\", \"it'll've\": \"it will have\",\"it's\": \"it is\", \"let's\": \"let us\",\n",
        "                    \"ma'am\": \"madam\", \"mayn't\": \"may not\", \"might've\": \"might have\",\"mightn't\": \"might not\",\"mightn't've\": \"might not have\",\n",
        "                    \"must've\": \"must have\", \"mustn't\": \"must not\", \"mustn't've\": \"must not have\", \"needn't\": \"need not\", \"needn't've\": \"need not have\",\n",
        "                    \"o'clock\": \"of the clock\", \"oughtn't\": \"ought not\", \"oughtn't've\": \"ought not have\", \"shan't\": \"shall not\", \"sha'n't\": \"shall not\",\n",
        "                    \"shan't've\": \"shall not have\", \"she'd\": \"she would\", \"she'd've\": \"she would have\", \"she'll\": \"she will\", \"she'll've\": \"she will have\",\n",
        "                    \"she's\": \"she is\", \"should've\": \"should have\", \"shouldn't\": \"should not\", \"shouldn't've\": \"should not have\", \"so've\": \"so have\",\n",
        "                    \"so's\": \"so as\", \"this's\": \"this is\",\"that'd\": \"that would\", \"that'd've\": \"that would have\", \"that's\": \"that is\", \"there'd\": \"there would\",\n",
        "                    \"there'd've\": \"there would have\", \"there's\": \"there is\", \"here's\": \"here is\",\"they'd\": \"they would\", \"they'd've\": \"they would have\",\n",
        "                    \"they'll\": \"they will\", \"they'll've\": \"they will have\", \"they're\": \"they are\", \"they've\": \"they have\", \"to've\": \"to have\", \"wasn't\": \"was not\",\n",
        "                    \"we'd\": \"we would\", \"we'd've\": \"we would have\", \"we'll\": \"we will\", \"we'll've\": \"we will have\", \"we're\": \"we are\", \"we've\": \"we have\",\n",
        "                    \"weren't\": \"were not\", \"what'll\": \"what will\", \"what'll've\": \"what will have\", \"what're\": \"what are\",  \"what's\": \"what is\", \"what've\": \"what have\",\n",
        "                    \"when's\": \"when is\", \"when've\": \"when have\", \"where'd\": \"where did\", \"where's\": \"where is\", \"where've\": \"where have\", \"who'll\": \"who will\",\n",
        "                    \"who'll've\": \"who will have\", \"who's\": \"who is\", \"who've\": \"who have\", \"why's\": \"why is\", \"why've\": \"why have\", \"will've\": \"will have\",\n",
        "                    \"won't\": \"will not\", \"won't've\": \"will not have\", \"would've\": \"would have\", \"wouldn't\": \"would not\", \"wouldn't've\": \"would not have\",\n",
        "                    \"y'all\": \"you all\", \"y'all'd\": \"you all would\",\"y'all'd've\": \"you all would have\",\"y'all're\": \"you all are\",\"y'all've\": \"you all have\",\n",
        "                    \"you'd\": \"you would\", \"you'd've\": \"you would have\", \"you'll\": \"you will\", \"you'll've\": \"you will have\", \"you're\": \"you are\", \"you've\": \"you have\"}\n",
        "\n",
        "stop_words = set(stopwords.words('english'))\n",
        "lemmatizer = WordNetLemmatizer()\n",
        "stemmer = PorterStemmer()\n",
        "\n",
        "def pre_process(sent_list):\n",
        "    output = []\n",
        "    for sent in tqdm(sent_list):\n",
        "        sent = sent.lower()  # case-folding\n",
        "        for word, new_word in contraction_dict.items():\n",
        "            sent = sent.replace(word, new_word)  # dealing with contractions\n",
        "        sent = re.sub(r'[^\\w\\s]', '', sent)  # removing punctuation\n",
        "        tokens = word_tokenize(sent)  # tokenization\n",
        "        tokens = [word for word in tokens if word not in stop_words]\n",
        "        tokens = [lemmatizer.lemmatize(word) for word in tokens]\n",
        "        tokens = [stemmer.stem(word) for word in tokens]\n",
        "        if len(tokens) > 0:\n",
        "          output.append([\"<BOS>\"] + tokens + [\"<EOS>\"])\n",
        "        else:\n",
        "          output.append(tokens)\n",
        "    return output\n",
        "\n",
        "# Preprocessing the data using the function defined above\n",
        "input_token_list_claim = pre_process(train_claim_list)  # -> input to encoder\n",
        "input_token_list_evidence = pre_process(train_evidence_list)\n",
        "dev_input_token_list_claim = pre_process(dev_claim_list)  # -> input to encoder\n",
        "dev_input_token_list_evidence = pre_process(dev_evidence_list)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "2Z9V3EfKrX8T"
      },
      "outputs": [],
      "source": [
        "# Here we simply use the maximum sentence length\n",
        "MAX_LENGTH = max([len(s) for s in input_token_list_claim]+[len(s) for s in input_token_list_evidence])\n",
        "MAX_LENGTH = 96"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "all_lengths = [len(s) for s in input_token_list_claim] + [len(s) for s in input_token_list_evidence]\n",
        "\n",
        "# calculate the avg length for texts\n",
        "average_length = sum(all_lengths) / len(all_lengths)"
      ],
      "metadata": {
        "id": "a3RwaPDl_lhs"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "YPkQWL4craiC"
      },
      "outputs": [],
      "source": [
        "# set up a vocab to index dictionary\n",
        "word_to_ix = {\"<BOS>\": 0, \"<EOS>\":1, \"<UNK>\":2}\n",
        "for sentence in input_token_list_claim + input_token_list_evidence:\n",
        "    for word in sentence:\n",
        "        if word not in word_to_ix:\n",
        "            word_to_ix[word] = len(word_to_ix)\n",
        "word_list = list(word_to_ix.keys())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "4FpVRFIcrcm6"
      },
      "outputs": [],
      "source": [
        "# construct token index lists for input\n",
        "# i.e., to convert each sequence into corresponding index based on the index dictionary we created in the previous section\n",
        "# e.g., ['are', 'your', 'systems', 'functioning'] -> [42, 6, 2576, 2577]\n",
        "unk_index = word_to_ix.get(\"<UNK>\", 2)\n",
        "def to_index(data, to_ix):\n",
        "    input_index_list = []\n",
        "    for sent in data:\n",
        "        input_index_list.append([float(to_ix.get(w, unk_index)) for w in sent])\n",
        "    return input_index_list\n",
        "\n",
        "input_index_1 = to_index(input_token_list_claim, word_to_ix)\n",
        "input_index_2 = to_index(input_token_list_evidence, word_to_ix)\n",
        "dev_input_index_1 = to_index(dev_input_token_list_claim, word_to_ix)\n",
        "dev_input_index_2 = to_index(dev_input_token_list_evidence, word_to_ix)\n",
        "dev_train_input_index_1 = input_index_1 + dev_input_index_1\n",
        "dev_train_input_index_2 = input_index_2 + dev_input_index_2"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cW2ilCfn6ATV"
      },
      "source": [
        "### dataloader implementation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "Lkk63A89t8JZ"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "\n",
        "MAX_LENGTH = 96\n",
        "max_len = MAX_LENGTH\n",
        "padding_index = word_to_ix[\"<EOS>\"]\n",
        "def seq_collate_batch(batch):\n",
        "    claim_list,evidence_list = [],[]\n",
        "    for  claim_text,evidence_text in batch:\n",
        "        claim_list.append(claim_text)\n",
        "        evidence_list.append(evidence_text)\n",
        "\n",
        "    # Pad or truncate each sequence\n",
        "    padded_sequences = []\n",
        "    for seq in claim_list:\n",
        "        # Truncate if longer than max_len\n",
        "        padded_seq = seq[:max_len]\n",
        "         # Pad if shorter\n",
        "        padded_seq += [padding_index] * (max_len - len(padded_seq))\n",
        "        padded_sequences.append(torch.LongTensor(padded_seq))\n",
        "    claim_list = torch.stack(padded_sequences)\n",
        "    # Pad or truncate each sequence\n",
        "    padded_sequences = []\n",
        "    for seq in evidence_list:\n",
        "        # Truncate if longer than max_len\n",
        "        padded_seq = seq[:max_len]\n",
        "         # Pad if shorter\n",
        "        padded_seq += [padding_index] * (max_len - len(padded_seq))\n",
        "        padded_sequences.append(torch.LongTensor(padded_seq))\n",
        "    evidence_list = torch.stack(padded_sequences)\n",
        "    # Stack all sequences into a single tensor\n",
        "    return claim_list.to(device), evidence_list.to(device)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "4jzoVaYG6Ek4"
      },
      "outputs": [],
      "source": [
        "train_dataloader = torch.utils.data.DataLoader(list(zip(input_index_1, input_index_2)), batch_size=8, shuffle=True, collate_fn=seq_collate_batch)\n",
        "dev_dataloader = torch.utils.data.DataLoader(list(zip(dev_input_index_1, dev_input_index_2)), batch_size=4, shuffle=True, collate_fn=seq_collate_batch)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NBkLm88CrfZI"
      },
      "source": [
        "### models"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "4j-XENAtr5PO"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch import optim\n",
        "import torch.nn.functional as F\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Bi-LSTM model implementation"
      ],
      "metadata": {
        "id": "m0Gq-RpPk6Ds"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "hHZtP_B0nKd6"
      },
      "outputs": [],
      "source": [
        "import torch.nn as nn\n",
        "import torch\n",
        "\n",
        "class EncoderBiLSTM(nn.Module):\n",
        "    def __init__(self, hidden_size, input_size,embedding):\n",
        "        super(EncoderBiLSTM, self).__init__()\n",
        "        self.hidden_size = hidden_size\n",
        "        self.embedding = embedding\n",
        "\n",
        "        self.lstm = nn.LSTM(input_size, hidden_size, bidirectional=True,batch_first=True)\n",
        "\n",
        "    def forward(self, x, hc):\n",
        "        embedded = self.embedding(x)\n",
        "        output, (h_n, c_n) = self.lstm(embedded,hc)\n",
        "\n",
        "        # h_n shape (num_layers * num_directions, hidden_size)\n",
        "        # For Bi-LSTM, num_directions = 2\n",
        "        forward_hidden = h_n[-2, :]\n",
        "        backward_hidden = h_n[-1, :]\n",
        "        forward_cell = c_n[-2, :]\n",
        "        backward_cell = c_n[-1, :]\n",
        "        embeddings = torch.cat((forward_hidden, backward_hidden), dim=1)\n",
        "        return output, embeddings, (forward_cell,backward_cell), (h_n, c_n)\n",
        "\n",
        "    def initHidden(self,batch_size):\n",
        "        num_directions = 2\n",
        "        return (torch.zeros(num_directions,batch_size, self.hidden_size, device=device),\n",
        "                torch.zeros(num_directions,batch_size, self.hidden_size, device=device))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "iko6uhNAroj4"
      },
      "outputs": [],
      "source": [
        "def train(input_tensor_1, input_tensor_2, encoder_1, encoder_2, encoder_optimizer_1, encoder_optimizer_2, max_length=MAX_LENGTH):\n",
        "\n",
        "    loss = 0\n",
        "    encoder_optimizer_1.zero_grad()\n",
        "    encoder_optimizer_2.zero_grad()\n",
        "\n",
        "    # get the embeddings for claims and evidences inside a batch (shape:  batch_size * hidden_size)\n",
        "    encoder_output_1, claim_embeddings, _, _ = encoder_1(input_tensor_1, encoder_1.initHidden(input_tensor_1.shape[0]))\n",
        "    encoder_output_2, evidence_embeddings, _, _ = encoder_2(input_tensor_2, encoder_2.initHidden(input_tensor_2.shape[0]))\n",
        "    #print(claim_embeddings.shape)\n",
        "    claim_embeddings = claim_embeddings.reshape(-1, 2 * hidden_size)\n",
        "    evidence_embeddings = evidence_embeddings.reshape(-1, 2 * hidden_size)\n",
        "    #caculate a similarity matrix for dot product of claim and evidence embeddings inside a batch\n",
        "    similarity_matrix =  torch.matmul(claim_embeddings, evidence_embeddings.T)\n",
        "\n",
        "    claim_to_evidences = {}\n",
        "\n",
        "    for i,input_1 in enumerate(input_tensor_1):\n",
        "        for j, input_2 in enumerate(input_tensor_1):\n",
        "            if torch.equal(input_1,input_2):\n",
        "               claim_to_evidences.update({i:j})\n",
        "\n",
        "    if len(claim_to_evidences) > 32:\n",
        "        print(claim_to_evidences)\n",
        "    batch_size = input_tensor_1.shape[0]\n",
        "    labels = torch.zeros((batch_size, batch_size)).to(similarity_matrix.device)\n",
        "    for claim_idx, evidence_idx in claim_to_evidences.items():\n",
        "        labels[claim_idx, evidence_idx] = 1\n",
        "\n",
        "    log_probs = F.log_softmax(similarity_matrix, dim=1)\n",
        "\n",
        "    loss = -torch.sum(log_probs * labels) / torch.sum(labels)\n",
        "\n",
        "    loss.backward()\n",
        "    encoder_optimizer_1.step()\n",
        "    encoder_optimizer_2.step()\n",
        "\n",
        "    return loss.item()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "YbjCehUarqG_"
      },
      "outputs": [],
      "source": [
        "import time\n",
        "import math\n",
        "\n",
        "# Helper functions for training\n",
        "def asMinutes(s):\n",
        "    m = math.floor(s / 60)\n",
        "    s -= m * 60\n",
        "    return '%dm %ds' % (m, s)\n",
        "\n",
        "def timeSince(since, percent):\n",
        "    now = time.time()\n",
        "    s = now - since\n",
        "    es = s / (percent)\n",
        "    rs = es - s\n",
        "    return '%s (- %s)' % (asMinutes(s), asMinutes(rs))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "8V0-8rJzrrhX"
      },
      "outputs": [],
      "source": [
        "import random\n",
        "from tqdm import tqdm\n",
        "def trainIters(encoder_1, encoder_2,dataloader, epochs,learning_rate=1e-4):\n",
        "    start = time.time()\n",
        "\n",
        "    encoder_optimizer_1 = optim.Adam(encoder_1.parameters(), lr=learning_rate)\n",
        "    encoder_optimizer_2 = optim.Adam(encoder_2.parameters(), lr=learning_rate)\n",
        "\n",
        "    for iter in range(epochs):\n",
        "        size = len(dataloader.dataset)\n",
        "        for batch, (input_tensor_1, input_tensor_2) in enumerate(dataloader):\n",
        "\n",
        "            loss = train(input_tensor_1, input_tensor_2, encoder_1, encoder_2, encoder_optimizer_1, encoder_optimizer_2)\n",
        "        print(\"epoch:\" + str(iter) + \" loss: \" + str(loss))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TeruySH3rtC8",
        "outputId": "b23a7fec-80bb-48f2-a050-419f0db6e8c5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch:0 loss: 0.6487799286842346\n",
            "epoch:1 loss: 0.8724571466445923\n",
            "epoch:2 loss: 0.49407118558883667\n",
            "epoch:3 loss: 0.10495072603225708\n",
            "epoch:4 loss: 0.052710555493831635\n",
            "epoch:5 loss: 0.01569930650293827\n",
            "epoch:6 loss: 0.00021542527247220278\n",
            "epoch:7 loss: 0.058339111506938934\n",
            "epoch:8 loss: 0.002314769197255373\n",
            "epoch:9 loss: 0.0003003384335897863\n",
            "epoch:10 loss: 0.00010030500561697409\n",
            "epoch:11 loss: 5.483381755766459e-05\n",
            "epoch:12 loss: 0.002915847348049283\n",
            "epoch:13 loss: 0.00017878196376841515\n",
            "epoch:14 loss: 2.7894195227418095e-05\n",
            "epoch:15 loss: 7.771843229420483e-05\n",
            "epoch:16 loss: 0.005906157195568085\n",
            "epoch:17 loss: 0.00020160229178145528\n",
            "epoch:18 loss: 5.9604641222676946e-08\n",
            "epoch:19 loss: 5.125981715536909e-06\n",
            "epoch:20 loss: 6.746986764483154e-05\n",
            "epoch:21 loss: 0.0015716117341071367\n",
            "epoch:22 loss: 1.4364518392540049e-05\n",
            "epoch:23 loss: 2.145764938177308e-06\n",
            "epoch:24 loss: 6.616093742195517e-06\n"
          ]
        }
      ],
      "source": [
        "hidden_size = 200\n",
        "embedding = nn.Embedding(len(word_to_ix), hidden_size,padding_idx = padding_index)\n",
        "encoder1 = EncoderBiLSTM(hidden_size, hidden_size, embedding).to(device)\n",
        "encoder2 = EncoderBiLSTM(hidden_size, hidden_size, embedding).to(device)\n",
        "trainIters(encoder1, encoder2, train_dataloader,epochs = 25)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EzGuzHPE87Ya"
      },
      "source": [
        "# 3.Testing and Evaluation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZXO-EFl8_WgW"
      },
      "source": [
        "## predict on the test set"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "id": "kC7VtE0mCvkX"
      },
      "outputs": [],
      "source": [
        "#read the test dataset json files\n",
        "with open('/content/COMP90042_2024/data/test-claims-unlabelled.json', 'r') as f:\n",
        "  test_claims = json.load(f)\n",
        "\n",
        "test_evidence_ids = set()\n",
        "# Initialize an empty list to store the paired data"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### pre-compute all evidence embeddings in advance and index them using FAISS"
      ],
      "metadata": {
        "id": "hkmfr0So_T40"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "preprocess all evidence text"
      ],
      "metadata": {
        "id": "90_DM1va_rqE"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uNHi5sKKS0Yz",
        "outputId": "3ffc2c24-fd9a-4d8c-cec9-6cc35da32af3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1208827/1208827 [00:01<00:00, 1053088.42it/s]\n",
            "100%|██████████| 1208827/1208827 [13:00<00:00, 1547.99it/s]\n",
            "1208827it [00:00, 2339573.47it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1208577\n",
            "1208827\n",
            "1208577\n"
          ]
        }
      ],
      "source": [
        "from tqdm import tqdm\n",
        "all_evidence_text_list = []\n",
        "all_evidence_id_list = []\n",
        "processed_all_evidence_text_list = []\n",
        "for evidence_id, evidence_text in tqdm(evidence_data.items()):\n",
        "    all_evidence_text_list.append(evidence_text)\n",
        "    all_evidence_id_list.append(evidence_id)\n",
        "\n",
        "processed_all_evidence_text_list = pre_process(all_evidence_text_list)\n",
        "# filter out the corresponding evidence id which has empty evidence text\n",
        "processed_all_evidence_id_list = [\n",
        "    evidence_id for evidence_id, evidence_text in tqdm(zip(all_evidence_id_list, processed_all_evidence_text_list))\n",
        "    if evidence_text and not (evidence_text == \"<BOS><EOS>\")\n",
        "]\n",
        "\n",
        "processed_all_evidence = dict(zip(processed_all_evidence_id_list, [text for text in processed_all_evidence_text_list if text]))\n",
        "\n",
        "print(len(processed_all_evidence_id_list))\n",
        "print(len(all_evidence_text_list))\n",
        "print(len(processed_all_evidence))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 62,
      "metadata": {
        "id": "xhpdz5bmwbfy"
      },
      "outputs": [],
      "source": [
        "json.dump(processed_all_evidence, open('/content/processed_all_evidence.json', 'w'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JLDJqb9M86e2"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "QvXOvAYlHUH_"
      },
      "outputs": [],
      "source": [
        "#load the processed_all_evidence.json\n",
        "import json\n",
        "with open('/content/drive/MyDrive/COMP90042_PROJECT/processed_all_evidence.json', 'r') as f:\n",
        "  processed_all_evidence = json.load(f)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UOcFvZTWMzmv",
        "outputId": "afcac8a7-57f3-46ff-fb3f-73e7bd17f19d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: faiss-cpu in /usr/local/lib/python3.10/dist-packages (1.8.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from faiss-cpu) (1.25.2)\n"
          ]
        }
      ],
      "source": [
        "!pip install faiss-cpu"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Compute the evidence embeddings using the trained evidence encoder (encoder2)"
      ],
      "metadata": {
        "id": "Fd-LTFvh_t4j"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "processed_all_evidence_list = []\n",
        "processed_all_evidence_text_list = []\n",
        "for evidence_id, evidence_text in tqdm(processed_all_evidence.items()):\n",
        "    processed_all_evidence_text_list.append(evidence_text)\n",
        "all_evidence_input_index_list = to_index(processed_all_evidence_text_list,word_to_ix)\n",
        "\n",
        "evidence_ids = list(processed_all_evidence.keys())\n",
        "processed_all_evidence_list = list(zip(evidence_ids, all_evidence_input_index_list))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pxnANMriMN3P",
        "outputId": "aee99a08-16db-4c7d-b3c4-745a0351be66"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1208577/1208577 [00:00<00:00, 1336766.27it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "max_len = MAX_LENGTH\n",
        "padding_index = word_to_ix[\"<EOS>\"]\n",
        "def test_collate_batch(batch):\n",
        "    text_list,id_list = [],[]\n",
        "    for  _id, _text in batch:\n",
        "        text_list.append(_text)\n",
        "        id_list.append(_id)\n",
        "    # Pad or truncate each sequence\n",
        "    padded_sequences = []\n",
        "    for seq in text_list:\n",
        "        # Truncate if longer than max_len\n",
        "        padded_seq = seq[:max_len]\n",
        "         # Pad if shorter\n",
        "        padded_seq += [padding_index] * (max_len - len(padded_seq))\n",
        "        #print(len(padded_seq))\n",
        "        padded_sequences.append(torch.LongTensor(padded_seq))\n",
        "    text_list = torch.stack(padded_sequences)\n",
        "\n",
        "    return id_list, text_list.to(device)\n",
        "\n",
        "evidence_dataloader = torch.utils.data.DataLoader(processed_all_evidence_list, batch_size=512, shuffle=True, collate_fn=test_collate_batch)"
      ],
      "metadata": {
        "id": "4vwWVxP0B6PF"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "evidence_embeddings = {}\n",
        "with torch.no_grad():\n",
        "    for batch, (evidence_id_batch, evidence_input_index_tensor_batch) in enumerate(tqdm(evidence_dataloader)):\n",
        "        encoder_output, encoder_embedding, _, last_encoder_hidden_cell = encoder2(evidence_input_index_tensor_batch, encoder2.initHidden(evidence_input_index_tensor_batch.shape[0]))\n",
        "\n",
        "        for _id, _hidden in zip(evidence_id_batch, encoder_embedding):\n",
        "            evidence_embeddings.update({_id:_hidden})\n"
      ],
      "metadata": {
        "id": "cWQhbMFy_5Dx",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "21d62c55-fdd1-49d1-cd77-c47282b3de68"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 2361/2361 [01:19<00:00, 29.86it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "evidence_embeddings_list = []\n",
        "evidence_embeddings_list = [evidence_embeddings[evidence_id].cpu() for evidence_id in evidence_ids]"
      ],
      "metadata": {
        "id": "57bg-xi4lctC"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import faiss\n",
        "evidence_embeddings_list = np.array(evidence_embeddings_list)\n",
        "vector_dimension = evidence_embeddings_list.shape[1]\n",
        "index = faiss.IndexFlatIP(vector_dimension)\n",
        "faiss.normalize_L2(evidence_embeddings_list)\n",
        "index.add(evidence_embeddings_list)"
      ],
      "metadata": {
        "id": "fOO4u0LKKCzs"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### compute the claim embeddings and evaluate the model on dev dataset"
      ],
      "metadata": {
        "id": "nWYIUvYROdNs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dev_claims_text_list = [claim_infor['claim_text'] for claim_id,claim_infor in dev_claims_data.items()]\n",
        "dev_claims_input_index_list = to_index(pre_process(dev_claims_text_list),word_to_ix)\n",
        "dev_claims_id_list = list(dev_claims_data.keys())\n",
        "dev_claims_input_list = list(zip(dev_claims_id_list, dev_claims_input_index_list))\n",
        "dev_claim_dataloader = torch.utils.data.DataLoader(dev_claims_input_list, batch_size=64, shuffle=True, collate_fn=test_collate_batch)"
      ],
      "metadata": {
        "id": "3wcuLF1XOcO2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "22a43f2b-1086-4953-844a-1c6358644988"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 154/154 [00:00<00:00, 2056.07it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dev_claim_retrieved_evidence = {}\n",
        "with torch.no_grad():\n",
        "    for batch, (claim_id_batch, claim_input_index_tensor_batch) in enumerate(tqdm(dev_claim_dataloader)):\n",
        "        encoder_output, encoder_embedding, _, last_encoder_hidden_cell = encoder1(claim_input_index_tensor_batch, encoder1.initHidden(claim_input_index_tensor_batch.shape[0]))\n",
        "        k = 3  # Number of nearest neighbors to retrieve\n",
        "        encoder_embedding = encoder_embedding.cpu().numpy()\n",
        "        faiss.normalize_L2(encoder_embedding)\n",
        "        distances, indices = index.search(encoder_embedding, k)\n",
        "        for i, claim_id in enumerate(claim_id_batch):\n",
        "            dev_claim_retrieved_evidence.update({claim_id: [evidence_ids[idx] for idx in indices[i]] })"
      ],
      "metadata": {
        "id": "GdGhCVvLXMPk",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "dc741c94-606a-47e3-8b29-3fe58bd6dd7a"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 3/3 [00:04<00:00,  1.39s/it]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dev_claim_ids = set([claim_id for claim_id,claim_infor in dev_claims_data.items()])\n",
        "\n",
        "true_positive = 0\n",
        "false_positive = 0\n",
        "false_negative = 0\n",
        "for claim_id in dev_claim_ids:\n",
        "    gold_evidence = set([evidence_id for evidence_id in dev_claims_data[claim_id]['evidences']])\n",
        "    predicted_evidence = set([evidence_id for evidence_id in dev_claim_retrieved_evidence[claim_id]])\n",
        "    true_positive += len(gold_evidence & predicted_evidence)\n",
        "    false_positive += len(predicted_evidence - gold_evidence)\n",
        "    false_negative += len(gold_evidence - predicted_evidence)\n",
        "\n",
        "accuracy_evidence_retrieval = true_positive / (true_positive + false_positive + false_negative)\n",
        "recall_evidence_retrieval = true_positive / (true_positive + false_negative)\n",
        "f1_evidence_retrieval = 2 * true_positive / (2 * true_positive + false_positive + false_negative)\n",
        "print(\"Evidence Retrieval\")\n",
        "print(\"Accuracy:\", accuracy_evidence_retrieval)\n",
        "print(\"Recall:\", recall_evidence_retrieval)\n",
        "print(\"F1 Score:\", f1_evidence_retrieval)"
      ],
      "metadata": {
        "id": "P6h3tOF7bLip",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7fc74a5f-5fe6-4b3a-be20-456ca673d50a"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Evidence Retrieval\n",
            "Accuracy: 0.005274261603375527\n",
            "Recall: 0.010183299389002037\n",
            "F1 Score: 0.01049317943336831\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### test set inference"
      ],
      "metadata": {
        "id": "bKciRBjn3ER4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "test_claims_text_list = [claim_infor[\"claim_text\"] for claim_id,claim_infor in test_claims.items()]\n",
        "test_claims_input_index_list = to_index(pre_process(test_claims_text_list),word_to_ix)\n",
        "test_claims_id_list = list(test_claims.keys())\n",
        "test_claims_input_list = list(zip(test_claims_id_list, test_claims_input_index_list))\n",
        "test_claim_dataloader = torch.utils.data.DataLoader(test_claims_input_list, batch_size=64, shuffle=True, collate_fn=test_collate_batch)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ukq_sxYjoyFW",
        "outputId": "a0103521-fe06-4a83-cd55-090a7d7c2a0c"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 153/153 [00:00<00:00, 1153.87it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_claim_retrieved_evidence = {}\n",
        "with torch.no_grad():\n",
        "    for batch, (claim_id_batch, claim_input_index_tensor_batch) in enumerate(tqdm(test_claim_dataloader)):\n",
        "        encoder_output, encoder_embedding, _, last_encoder_hidden_cell = encoder1(claim_input_index_tensor_batch, encoder1.initHidden(claim_input_index_tensor_batch.shape[0]))\n",
        "        k = 3  # Number of nearest neighbors to retrieve\n",
        "        distances, indices = index.search(encoder_embedding.cpu().numpy(), k)\n",
        "        for i, claim_id in enumerate(claim_id_batch):\n",
        "            test_claim_retrieved_evidence.update({claim_id: [evidence_ids[idx] for idx in indices[i]] })"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zfq6acM_3grF",
        "outputId": "abb2441e-bb15-4f66-8c88-0757f07e9f9a"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 3/3 [00:13<00:00,  4.64s/it]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for claim_id, claim_data in tqdm(test_claims.items(), desc=\"Processing Claims\"):\n",
        "    test_claims[claim_id]['claim_label'] = \"SUPPORTS\"\n",
        "    test_claims[claim_id]['evidences'] = []\n",
        "    for evidence_id in test_claim_retrieved_evidence[claim_id]:\n",
        "        test_claims[claim_id]['evidences'].append(evidence_id)\n",
        "\n",
        "json.dump(test_claims, open('/content/COMP90042_2024/data/test-output.json', 'w'))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9o7E9mAz5mdp",
        "outputId": "cd8f191f-eef4-4374-b179-3b57ce4036d8"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing Claims: 100%|██████████| 153/153 [00:00<00:00, 198554.61it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "0b-ei38bIx_a"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mefSOe8eTmGP"
      },
      "source": [
        "## Object Oriented Programming codes here\n",
        "\n",
        "*You can use multiple code snippets. Just add more if needed*"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}