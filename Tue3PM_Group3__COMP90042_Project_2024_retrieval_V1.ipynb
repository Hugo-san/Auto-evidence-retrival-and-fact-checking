{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "32yCsRUo8H33"
      },
      "source": [
        "# 2024 COMP90042 Project\n",
        "*Make sure you change the file name with your group id.*"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XCybYoGz8YWQ"
      },
      "source": [
        "# Readme\n",
        "1. The training can be quite slow under the environment of free Colab. It takes us 2.5 hours to run 5 epochs.\n",
        "2. At the end of the notebook, some json files are strored for the next part --- claim classification."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sHFtGNqCJgtg"
      },
      "source": [
        "**We use pytorch, nltk, scikit-learn in this project.**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6po98qVA8bJD"
      },
      "source": [
        "# 1.DataSet Processing\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1.1 Download the data from github"
      ],
      "metadata": {
        "id": "h0uKqKkRAYqt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "# the repository link:\n",
        "repository_url = 'https://github.com/drcarenhan/COMP90042_2024.git'\n",
        "\n",
        "# clone the repository\n",
        "os.system(f'git clone {repository_url}')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_yt-5QOhKheO",
        "outputId": "f9457d6c-cb66-4225-acd7-db3db26a59b2"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "32768"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "save_path = '/content/COMP90042_2024/data'\n",
        "os.makedirs(save_path, exist_ok=True)\n",
        "\n",
        "output_file_path = os.path.join(save_path, 'evidence.json')\n",
        "\n",
        "!gdown --id '1JlUzRufknsHzKzvrEjgw8D3n_IRpjzo6' -O {output_file_path}"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lOgwmiiFKi8B",
        "outputId": "be6959fa-6b13-4cd8-b02c-7c2306126bd3"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/gdown/__main__.py:132: FutureWarning: Option `--id` was deprecated in version 4.3.1 and will be removed in 5.0. You don't need to pass it anymore to use a file ID.\n",
            "  warnings.warn(\n",
            "Downloading...\n",
            "From (original): https://drive.google.com/uc?id=1JlUzRufknsHzKzvrEjgw8D3n_IRpjzo6\n",
            "From (redirected): https://drive.google.com/uc?id=1JlUzRufknsHzKzvrEjgw8D3n_IRpjzo6&confirm=t&uuid=c124f8eb-c9a6-47fc-8e0b-c16fbca66293\n",
            "To: /content/COMP90042_2024/data/evidence.json\n",
            "100% 174M/174M [00:01<00:00, 160MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "cd /content/COMP90042_2024/"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HRQh9SYdKlVl",
        "outputId": "0eb27c4c-beef-4ccf-9295-f4b25de78625"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/COMP90042_2024\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qvff21Hv8zjk",
        "tags": []
      },
      "source": [
        "## 1.2 PreProcess for evidence and claims"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-E1nmTPdJgtg"
      },
      "source": [
        "### 1.2.1 preprocessing function"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "This code of stemming, lemmatizing and stopword removal are referred from tutorial"
      ],
      "metadata": {
        "id": "_chk6qnQEAlx"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XQAsvi93Jgtg",
        "outputId": "bec6e6ad-1d0c-4f27-fe6b-36dc2a651590"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ]
        }
      ],
      "source": [
        "import string\n",
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "\n",
        "# Download necessary NLTK data files\n",
        "nltk.download('wordnet')\n",
        "nltk.download('stopwords')\n",
        "nltk.download('punkt')\n",
        "\n",
        "# Initialize the lemmatizer and stopwords\n",
        "lemmatizer = WordNetLemmatizer()\n",
        "stopwords_set = set(stopwords.words('english'))\n",
        "\n",
        "# Lemmatizer function\n",
        "def lemmatize(word):\n",
        "    lemma = lemmatizer.lemmatize(word, 'v')\n",
        "    if lemma == word:\n",
        "        lemma = lemmatizer.lemmatize(word, 'n')\n",
        "    return lemma\n",
        "\n",
        "# Text preprocessing function\n",
        "def text_preprocessing(text):\n",
        "    # Lowercasing\n",
        "    text = text.lower()\n",
        "\n",
        "    # Tokenizing\n",
        "    words = word_tokenize(text)\n",
        "\n",
        "    # Lemmatizing and removing stopwords\n",
        "    new_words = [lemmatize(w) for w in words if w not in stopwords_set]\n",
        "\n",
        "    return \" \".join(new_words)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zZNjwJPoJgth"
      },
      "source": [
        "### 1.2.2 read files"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Auxilary functions for reading and pre-processing the data."
      ],
      "metadata": {
        "id": "osPTY3BKRQBO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "\n",
        "def process_claims(claims, evidences_id_dict):\n",
        "    \"\"\"\n",
        "    Process claims data to extract relevant information and map evidence IDs.\n",
        "\n",
        "    Args:\n",
        "    claims (dict): A dictionary of claims where each key is a claim ID and each value is a dictionary containing claim details.\n",
        "    evidences_id_dict (dict): A dictionary mapping evidence IDs to indices for quick access.\n",
        "\n",
        "    Returns:\n",
        "    tuple: Contains lists of claim IDs, claim texts, preprocessed claim texts, associated evidence indices, and claim labels.\n",
        "    \"\"\"\n",
        "    ids = []\n",
        "    texts = []\n",
        "    processed_texts = []\n",
        "    evidences = []\n",
        "    labels = []\n",
        "\n",
        "    for claim_id, data in claims.items():\n",
        "        ids.append(claim_id)\n",
        "        texts.append(data[\"claim_text\"])\n",
        "        processed_texts.append(text_preprocessing(data[\"claim_text\"]))\n",
        "        labels.append(data.get(\"claim_label\", None))  # Test data have no labels.\n",
        "        evidences.append([evidences_id_dict[i] for i in data.get(\"evidences\", [])])\n",
        "\n",
        "    return ids, texts, processed_texts, evidences, labels\n",
        "\n",
        "def process_evidences(evidences):\n",
        "    \"\"\"\n",
        "    Process evidences data to extract relevant information and create a mapping from evidence IDs to indices.\n",
        "\n",
        "    Args:\n",
        "    evidences (dict): A dictionary of evidences where each key is an evidence ID and the value is the evidence text.\n",
        "\n",
        "    Returns:\n",
        "    tuple: Contains lists of evidence IDs, evidence texts, preprocessed evidence texts, and a dictionary mapping IDs to indices.\n",
        "    \"\"\"\n",
        "    ids = []\n",
        "    texts = []\n",
        "    processed_texts = []\n",
        "    id_dict = {}\n",
        "\n",
        "    for idx, (evidence_id, evidence_text) in enumerate(evidences.items()):\n",
        "        ids.append(evidence_id)\n",
        "        texts.append(evidence_text)\n",
        "        processed_texts.append(text_preprocessing(evidence_text))\n",
        "        id_dict[evidence_id] = idx\n",
        "\n",
        "    return ids, texts, processed_texts, id_dict"
      ],
      "metadata": {
        "id": "WNjhodxoRNjn"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Use the functions to read the data."
      ],
      "metadata": {
        "id": "Wp_uS7g5RWho"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "XDmBRQNQJgth"
      },
      "outputs": [],
      "source": [
        "# Load data from files\n",
        "with open(save_path+'/train-claims.json', 'r') as file:\n",
        "    train_claims = json.load(file)\n",
        "\n",
        "with open(save_path+'/evidence.json', 'r') as file:\n",
        "    evidences = json.load(file)\n",
        "\n",
        "with open(save_path+'/dev-claims.json', 'r') as file:\n",
        "    dev_claims = json.load(file)\n",
        "\n",
        "with open(save_path+'/test-claims-unlabelled.json', 'r') as file:\n",
        "    test_claims = json.load(file)\n",
        "\n",
        "# Process evidence data to prepare for linkage with claims\n",
        "evidences_ids, evidences_texts, evidences_p_texts, evidences_id_dict = process_evidences(evidences)\n",
        "\n",
        "# Process claims data for training, development, and test sets using the evidence dictionary\n",
        "train_ids, train_claim_texts, train_p_claim_texts, train_evidences, train_labels = process_claims(train_claims, evidences_id_dict)\n",
        "dev_ids, dev_claim_texts, dev_p_claim_texts, dev_evidences, dev_labels = process_claims(dev_claims, evidences_id_dict)\n",
        "test_ids, test_claim_texts, test_p_claim_texts, _, _ = process_claims(test_claims, evidences_id_dict)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "83pM2AR3Jgti"
      },
      "source": [
        "### 1.2.3 Construct TFIDF representations"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We use the TFIDF to pre-process the data to find potential relevant evidences that can be used for later training.\n",
        "\n",
        "Here, we transform them into TFIDF representations first."
      ],
      "metadata": {
        "id": "u9zC-BtaRcqT"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "tags": [],
        "id": "LiLiEjFwJgti"
      },
      "outputs": [],
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "\n",
        "# Initialize a TfidfVectorizer.\n",
        "# max_features limits the number of features (i.e., maximum number of distinct words) to consider to 500,000.\n",
        "# This helps in managing memory usage and improving processing speed.\n",
        "vectorizer = TfidfVectorizer(max_features=500000)\n",
        "\n",
        "# Fit the TfidfVectorizer to the entire set of claim and evidence texts.\n",
        "# This will compute the IDF (Inverse Document Frequency) values across all given texts,\n",
        "# and determine the vocabulary from the evidence texts.\n",
        "# Use all the processed claim and evidence texts to fit TFIDF\n",
        "vectorizer.fit(evidences_p_texts+train_p_claim_texts)\n",
        "\n",
        "# Transform the preprocessed texts of training claims into a TF-IDF-weighted document-term matrix.\n",
        "train_claim_tfidf = vectorizer.transform(train_p_claim_texts)\n",
        "\n",
        "# Similarly, transform the development and test set preprocessed texts into their respective\n",
        "# TF-IDF-weighted document-term matrices.\n",
        "dev_claim_tfidf = vectorizer.transform(dev_p_claim_texts)\n",
        "test_claim_tfidf = vectorizer.transform(test_p_claim_texts)\n",
        "\n",
        "# Transform the preprocessed texts of the evidences into a TF-IDF-weighted document-term matrix.\n",
        "# This allows comparison of claims with evidences based on their textual content.\n",
        "evidence_tfidf = vectorizer.transform(evidences_p_texts)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 1.2.4 Find the potential relevant evidences for each claim"
      ],
      "metadata": {
        "id": "dYKbQ5U5kSes"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "We also sort our potential evidences for each claim according to TFIDF. This is can provide potential relevant evidences for later model to train and predict. We calculate the similarity matrix in this function by TFIDF and we do this by splitting the claim into many parts with the length of \"claim_splits_length\" to avoid the crush of RAM in colab."
      ],
      "metadata": {
        "id": "gQjpGKToujYs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "def sort_evidence_candidates(claim_tfidf, evidence_tfidf, claim_splits_length):\n",
        "    \"\"\"\n",
        "    Sorts evidence candidates for claims based on cosine similarity scores between claim and evidence TF-IDF vectors.\n",
        "\n",
        "    Args:\n",
        "    claim_tfidf (sparse matrix): A TF-IDF weighted document-term matrix for the claims.\n",
        "    evidence_tfidf (sparse matrix): A TF-IDF weighted document-term matrix for the evidences.\n",
        "    claim_splits_length (int): The number of claims to process in each batch.\n",
        "\n",
        "    Returns:\n",
        "    list of lists: Each sublist contains the indices of the top 1000 most similar evidences for each claim.\n",
        "    \"\"\"\n",
        "    i = 0\n",
        "    potential_evidences = []\n",
        "    # Loop through each batch of claims\n",
        "    while i * claim_splits_length < claim_tfidf.shape[0]:\n",
        "        # Calculate cosine similarity between a batch of claims and all evidences.\n",
        "        # The result is a matrix where each row corresponds to a claim and each column to an evidence.\n",
        "        cos_sims = np.dot(\n",
        "            claim_tfidf[i * claim_splits_length:min((i + 1) * claim_splits_length, claim_tfidf.shape[0])],\n",
        "            evidence_tfidf.transpose()\n",
        "        ).toarray()\n",
        "\n",
        "        # For each claim in the current batch, find the indices of the top 1000 most similar evidences.\n",
        "        for j in range(cos_sims.shape[0]):\n",
        "            top_potential_evidence_ids = np.argsort(-cos_sims[j]).tolist()[:1000]\n",
        "            potential_evidences.append(top_potential_evidence_ids)\n",
        "        i += 1\n",
        "\n",
        "    return potential_evidences"
      ],
      "metadata": {
        "id": "YtuH8Yb-KtzJ"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Use the defined function to get the potential evidences for claims"
      ],
      "metadata": {
        "id": "cyTj9dBm8r55"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_sort_potential_evidences = sort_evidence_candidates(train_claim_tfidf, evidence_tfidf, 100)\n",
        "dev_sort_potential_evidences = sort_evidence_candidates(dev_claim_tfidf, evidence_tfidf, 100)\n",
        "test_sort_potential_evidences = sort_evidence_candidates(test_claim_tfidf, evidence_tfidf, 100)"
      ],
      "metadata": {
        "id": "BVcDnvIvKvl2"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EFvgzRt2Jgtj"
      },
      "source": [
        "### 1.2.5 Construct vocab and indexing"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "In this part we construc the vocab indexing for our model. The related code are referred from workshops."
      ],
      "metadata": {
        "id": "o5IwA41L_WfG"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "tags": [],
        "id": "MnOhZm5lJgtj"
      },
      "outputs": [],
      "source": [
        "def build_vocabulary(texts, min_count=3):\n",
        "    \"\"\"\n",
        "    Build a vocabulary from a list of texts, filtering words by a minimum count threshold.\n",
        "\n",
        "    Args:\n",
        "    texts (list of str): A list of sentences from which to build the vocabulary.\n",
        "    min_count (int): Minimum occurrence threshold for words to be included in the vocabulary.\n",
        "\n",
        "    Returns:\n",
        "    tuple: Two dictionaries - idx2word (maps index to word) and word2idx (maps word to index).\n",
        "    \"\"\"\n",
        "    # Initialize word count dictionary and predefined special tokens.\n",
        "    wordcount = {}\n",
        "    idx2word = [\"<pad>\", \"<cls>\", \"<sep>\", \"<unk>\"]\n",
        "    word2idx = {\"<pad>\": 0, \"<cls>\": 1, \"<sep>\": 2, \"<unk>\": 3}\n",
        "\n",
        "    # Count occurrences of each word in the texts.\n",
        "    for text in texts:\n",
        "        for word in text.split():\n",
        "            wordcount[word] = wordcount.get(word, 0) + 1\n",
        "\n",
        "    # Start indexing for new words from 4 since 0-3 are reserved for special tokens.\n",
        "    idx = len(idx2word)\n",
        "\n",
        "    # Include words in the vocabulary only if they meet the minimum count criteria.\n",
        "    for word, count in wordcount.items():\n",
        "        if count > min_count:\n",
        "            idx2word.append(word)\n",
        "            word2idx[word] = idx\n",
        "            idx += 1\n",
        "\n",
        "    return idx2word, word2idx\n",
        "\n",
        "# Use the function to build the vocabulary from training and evidence texts.\n",
        "idx2word, word2idx = build_vocabulary(train_claim_texts + evidences_texts, min_count=3)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "tags": [],
        "id": "aO4YJSIZJgtj"
      },
      "outputs": [],
      "source": [
        "def convert_to_indices(text_data, word2idx):\n",
        "    \"\"\"\n",
        "    Convert a list of sentences into lists of indices based on a given word-to-index mapping.\n",
        "\n",
        "    Args:\n",
        "    text_data (list of str): A list of sentences to be converted.\n",
        "    word2idx (dict): A dictionary mapping words to their corresponding indices.\n",
        "\n",
        "    Returns:\n",
        "    list of list of int: A list where each sentence is represented as a list of indices.\n",
        "    \"\"\"\n",
        "    # Initialize the list that will store the converted sentences.\n",
        "    idx_data = []\n",
        "\n",
        "    # Iterate over each sentence in the input list.\n",
        "    for text in text_data:\n",
        "        # Convert each word in the sentence to its corresponding index.\n",
        "        # If the word is not found in the dictionary, use the index for \"<unk>\".\n",
        "        indices = [word2idx.get(word, word2idx[\"<unk>\"]) for word in text.split()]\n",
        "\n",
        "        # Append the list of indices to the main list.\n",
        "        idx_data.append(indices)\n",
        "\n",
        "    return idx_data"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Use the defined function to convert the words in texts into indices."
      ],
      "metadata": {
        "id": "ltKNTJ1MHp27"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "tags": [],
        "id": "1eWUbC5aJgtj"
      },
      "outputs": [],
      "source": [
        "train_claim_text_idx = convert_to_indices(train_claim_texts, word2idx)\n",
        "dev_claim_text_idx = convert_to_indices(dev_claim_texts, word2idx)\n",
        "test_claim_text_idx = convert_to_indices(test_claim_texts, word2idx)\n",
        "evidences_text_idx = convert_to_indices(evidences_texts, word2idx)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Perform a statistics on the length of claim texts and evidence texts. This help us determine the length for padding and truncating."
      ],
      "metadata": {
        "id": "QqkJ1380H175"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "tags": [],
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-Tlkdz6QJgtj",
        "outputId": "6a9e7977-9d73-4ca5-ee33-0bca544be2e5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train - Average: 20.09771986970684, Median: 19.0,Max: 67\n",
            "Dev - Average: 21.084415584415584, Median: 18.0,Max: 65\n",
            "Test - Average: 20.03921568627451, Median: 19.0,Max: 53\n",
            "Evidence - Average: 19.691925312720514, Median: 18.0,Max: 479\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "\n",
        "def calculate_statistics(text_indices):\n",
        "    \"\"\"\n",
        "    Calculate the average and median lengths of lists of indices.\n",
        "\n",
        "    Args:\n",
        "    text_indices (list of list of int): A list where each inner list contains indices for a sentence.\n",
        "\n",
        "    Returns:\n",
        "    tuple: A tuple containing the average length and the median length of the sentences.\n",
        "    \"\"\"\n",
        "    # Calculate the lengths of all sentences\n",
        "    lengths = [len(sentence) for sentence in text_indices]\n",
        "\n",
        "    # Compute the average length of the sentences\n",
        "    average_length = np.mean(lengths)\n",
        "\n",
        "    # Compute the median length of the sentences\n",
        "    median_length = np.median(lengths)\n",
        "\n",
        "    max_length = max(lengths)\n",
        "    return average_length, median_length, max_length\n",
        "\n",
        "# Calculate statistics for each dataset\n",
        "train_avg, train_med, train_max = calculate_statistics(train_claim_text_idx)\n",
        "dev_avg, dev_med, dev_max = calculate_statistics(dev_claim_text_idx)\n",
        "test_avg, test_med, test_max = calculate_statistics(test_claim_text_idx)\n",
        "evidence_avg, evidence_med, evidence_max = calculate_statistics(evidences_text_idx)\n",
        "\n",
        "# Print the statistics\n",
        "print(f\"Train - Average: {train_avg}, Median: {train_med},Max: {train_max}\")\n",
        "print(f\"Dev - Average: {dev_avg}, Median: {dev_med},Max: {dev_max}\")\n",
        "print(f\"Test - Average: {test_avg}, Median: {test_med},Max: {test_max}\")\n",
        "print(f\"Evidence - Average: {evidence_avg}, Median: {evidence_med},Max: {evidence_max}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "So we can set the reasonable length for padding and truncating according to our statistics result shown above. But this hyperparameter can also be tuned by experimenting with different values later."
      ],
      "metadata": {
        "id": "Du5-b12iKOx7"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "tags": [],
        "id": "QGgrisWaJgtk"
      },
      "outputs": [],
      "source": [
        "claim_pad_len = 50\n",
        "evidences_pad_len = 70"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "tags": [],
        "id": "xb4wmW76Jgtk"
      },
      "outputs": [],
      "source": [
        "def construct_input_text(text_indices, padding_length, word2idx):\n",
        "    \"\"\"\n",
        "    Construct input text arrays with special tokens and padding.\n",
        "\n",
        "    Args:\n",
        "    text_indices (list of list of int): A list of sentences, where each sentence is represented by a list of word indices.\n",
        "    padding_length (int): The fixed length to which all input texts should be padded or truncated.\n",
        "    word2idx (dict): A dictionary mapping words to their corresponding indices, must include special tokens.\n",
        "\n",
        "    Returns:\n",
        "    list of list of int: A list of processed texts, each converted to a list of indices with special tokens and padding.\n",
        "    \"\"\"\n",
        "    idx_data = []\n",
        "    # Iterate over each sentence represented by its indices.\n",
        "    for indices in text_indices:\n",
        "        # Check if the length of the current sentence is less than the padding length.\n",
        "        if len(indices) < padding_length:\n",
        "            # If less, pad the sentence. Start with the <cls> token, followed by the original sentence,\n",
        "            # and a <sep> token, then pad with <pad> tokens up to the required length.\n",
        "            padded_sentence = ([word2idx[\"<cls>\"]] + indices + [word2idx[\"<sep>\"]] +\n",
        "                               [word2idx[\"<pad>\"]] * (padding_length - len(indices)))\n",
        "        else:\n",
        "            # If the sentence is longer or equal to the padding length, truncate it after adding the initial <cls> token\n",
        "            # and end it with a <sep> token within the specified padding length.\n",
        "            padded_sentence = ([word2idx[\"<cls>\"]] + indices[:padding_length] + [word2idx[\"<sep>\"]])\n",
        "\n",
        "        # Add the processed sentence to the list.\n",
        "        idx_data.append(padded_sentence)\n",
        "\n",
        "    return idx_data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "tags": [],
        "id": "mNup5oUMJgtk"
      },
      "outputs": [],
      "source": [
        "train_claim_input = construct_input_text(train_claim_text_idx, claim_pad_len, word2idx)\n",
        "dev_claim_input = construct_input_text(dev_claim_text_idx, claim_pad_len, word2idx)\n",
        "test_claim_input = construct_input_text(test_claim_text_idx, claim_pad_len, word2idx)\n",
        "evidences_input = construct_input_text(evidences_text_idx, evidences_pad_len, word2idx)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Print the length to check whether the length is correct. Here the length is as expected because we added CLS and SEP token no matter whether the length is longer or shorter than padding length."
      ],
      "metadata": {
        "id": "q0nOTKUrRGK7"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "tags": [],
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kdyzl_zUJgtk",
        "outputId": "3c81646a-d6bc-43b4-e425-567f1900b28a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "52 52 52 72\n"
          ]
        }
      ],
      "source": [
        "print(max([len(i) for i in train_claim_input]), max([len(i) for i in dev_claim_input]), max([len(i) for i in test_claim_input]), max([len(i) for i in evidences_input]))"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1.3 Construct the dataloader"
      ],
      "metadata": {
        "id": "XyJgGZ2QUpeV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "In this part, we define how to load the batch of data for training, including the strategy for pairing a claim with negative and positive evidences."
      ],
      "metadata": {
        "id": "P_KFgxxvUyRS"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "tags": [],
        "id": "TmEQkL4MJgtl"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from torch.utils.data import Dataset\n",
        "import random\n",
        "\n",
        "random.seed(90042)\n",
        "\n",
        "class TrainDataset(Dataset):\n",
        "    \"\"\"\n",
        "    A dataset class for training the machine learning model that requires claim inputs,\n",
        "    potential relevant evidences, truly associated positive evidences, and a mechanism for handling negative sampling.\n",
        "    \"\"\"\n",
        "    def __init__(self, claim_input_data, evidence_input_data, sort_potential_evidences, positive_evidence, negative_num=10,negative_sample_start_idx=10):\n",
        "        \"\"\"\n",
        "        Initialize the dataset with text and evidence data.\n",
        "\n",
        "        Args:\n",
        "        claim_input_data (list): List of text inputs.\n",
        "        evidence_input_data (list): List of evidence inputs (all evidences).\n",
        "        sort_potential_evidences (list): List of potential evidence indices sorted by their TF-IDF similarity with claim.\n",
        "        positive_evidence (list): List of positive evidence for the claim input. (In this retrieval part, the positive means relavant)\n",
        "        negative_num (int): Number of negative samples of evidences to include.\n",
        "        \"\"\"\n",
        "        self.claim_input_data = claim_input_data\n",
        "        self.evidence_input_data = evidence_input_data\n",
        "        self.sort_potential_evidences = sort_potential_evidences\n",
        "        self.positive_evidence = positive_evidence\n",
        "        self.negative_num = negative_num\n",
        "        self.evidence_len = len(evidence_input_data[0]) if evidence_input_data else 0\n",
        "        self.claim_text_len = len(claim_input_data[0]) if claim_input_data else 0\n",
        "        self.negative_sample_start_idx = negative_sample_start_idx\n",
        "\n",
        "    def __len__(self):\n",
        "        \"\"\"Return the total number of items in the dataset.\"\"\"\n",
        "        return len(self.claim_input_data)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        \"\"\"\n",
        "        Retrieves an item from the dataset at the specified index.\n",
        "\n",
        "        Args:\n",
        "        idx (int): The index of the item.\n",
        "\n",
        "        Returns:\n",
        "        tuple: A tuple containing the claim input, selected negative evidences, and corresponding positive evidences.\n",
        "        \"\"\"\n",
        "        # Select negative evidences by sampling from tfidf sorted potential evidence indices excluding top 10.\n",
        "        negative_samples = random.sample(self.sort_potential_evidences[idx][self.negative_sample_start_idx: self.negative_num*20], self.negative_num)\n",
        "        return [self.claim_input_data[idx], negative_samples, self.positive_evidence[idx]]\n",
        "\n",
        "    def collate_fn(self, batch):\n",
        "        \"\"\"\n",
        "        Custom collate function to process a batch of data.\n",
        "\n",
        "        Args:\n",
        "        batch (list of tuples): A list of tuples from the __getitem__ method.\n",
        "\n",
        "        Returns:\n",
        "        dict: A dictionary containing tensors for claim, evidences, positions, and labels.\n",
        "        \"\"\"\n",
        "        claim, claim_pos, positive_evidences, evidences = [], [], [], []\n",
        "\n",
        "        # Unpack batch and process data\n",
        "        for claim_data, negative_samples, positive_evidence in batch:\n",
        "            claim.append(claim_data)\n",
        "            claim_pos.append(list(range(self.claim_text_len)))\n",
        "            positive_evidences.append(positive_evidence)\n",
        "            evidences.extend(positive_evidence + negative_samples)\n",
        "\n",
        "        # Create a new unique list of evidences inside this batch\n",
        "        unique_evidences, evidences_pos = list(set(evidences)), []\n",
        "        # Map the positive evidence to the indices of this new unique list for convenience of later calculating loss in training phase\n",
        "        evidences2idx = {evid: idx for idx, evid in enumerate(unique_evidences)}\n",
        "        positive_evidences = [[evidences2idx[evid] for evid in positive_evidence_set] for positive_evidence_set in positive_evidences]\n",
        "        # get all evidences used in this batch (Both negative and positive)\n",
        "        batch_evidences = [self.evidence_input_data[evid] for evid in unique_evidences]\n",
        "        batch_evidences_pos = [list(range(self.evidence_len)) for _ in unique_evidences]\n",
        "\n",
        "        # Pack everything into a dictionary as a instance of a batch\n",
        "        batch_data = {\n",
        "            \"claim_queries\": torch.LongTensor(claim),\n",
        "            \"claim_queries_pos\": torch.LongTensor(claim_pos),\n",
        "\n",
        "            \"batch_evidences\": torch.LongTensor(batch_evidences),\n",
        "            \"batch_evidences_pos\": torch.LongTensor(batch_evidences_pos),\n",
        "\n",
        "            \"positive_evidences\": positive_evidences\n",
        "        }\n",
        "\n",
        "        return batch_data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "tags": [],
        "id": "8aOL1Mb7Jgtl"
      },
      "outputs": [],
      "source": [
        "train_set = TrainDataset(train_claim_input, evidences_input, train_sort_potential_evidences,\n",
        "                         train_evidences, negative_num=10,negative_sample_start_idx=10)\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "dataloader = DataLoader(train_set, batch_size=5, shuffle=True, num_workers=1, collate_fn=train_set.collate_fn)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1FA2ao2l8hOg"
      },
      "source": [
        "# 2.Model Implementation\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Define our transformer based encoder. The code of this part is referred from workshops."
      ],
      "metadata": {
        "id": "eV6xv0IBlKnt"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "tags": [],
        "id": "ZfQRp2oQJgtl"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "class Encoder(nn.Module):\n",
        "    \"\"\"\n",
        "    A Transformer-based encoder module.\n",
        "\n",
        "    Args:\n",
        "    vocab_size (int): Size of the vocabulary.\n",
        "    embed_dim (int): Dimensionality of the embeddings.\n",
        "    hidden_size (int): Size of the hidden layer.\n",
        "    nhead (int): Number of attention heads in the TransformerEncoder.\n",
        "    num_layers (int): Number of layers in the TransformerEncoder.\n",
        "    max_position (int): Maximum sequence length for positional embeddings.\n",
        "    \"\"\"\n",
        "    def __init__(self, vocab_size, embed_dim, hidden_size, nhead, num_layers, max_position=180):\n",
        "        super(Encoder, self).__init__()\n",
        "\n",
        "        # Hidden size attribute for possible external use.\n",
        "        self.hidden_size = hidden_size\n",
        "\n",
        "        # Embedding layers for vocabulary and positional encodings.\n",
        "        self.embedding = nn.Embedding(vocab_size, embed_dim)\n",
        "        self.pos_embedding = nn.Embedding(max_position, embed_dim)\n",
        "\n",
        "        # Transformer encoder layer and complete encoder.\n",
        "        encoder_layer = nn.TransformerEncoderLayer(d_model=hidden_size, nhead=nhead, batch_first=True, dropout=0.1)\n",
        "        self.encoder = nn.TransformerEncoder(encoder_layer, num_layers=num_layers, norm=nn.LayerNorm(hidden_size))\n",
        "\n",
        "    def forward(self, text_data, position_text):\n",
        "        \"\"\"\n",
        "        Forward pass of the encoder model.\n",
        "\n",
        "        Args:\n",
        "        text_data (Tensor): Input text data (token indices).\n",
        "        position_text (Tensor): Positional indices associated with the text data.\n",
        "\n",
        "        Returns:\n",
        "        Tensor: Encoded output from the Transformer encoder.\n",
        "        \"\"\"\n",
        "        # Mask for padding tokens (usually zero).\n",
        "        mask_ = text_data == 0\n",
        "\n",
        "        # Add word embeddings and positional embeddings.\n",
        "        text_x = self.embedding(text_data) + self.pos_embedding(position_text)\n",
        "\n",
        "        # Apply the Transformer encoder.\n",
        "        x_encoded = self.encoder(text_x, src_key_padding_mask=mask_)\n",
        "        return x_encoded"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "vocab_size = len(idx2word)\n",
        "print(vocab_size)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QtktVFHie3qN",
        "outputId": "9869a089-9000-4bf1-bc22-e1ff3e7efcad"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "197728\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Initialize our encoder"
      ],
      "metadata": {
        "id": "NwjGJb9goV76"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "scrolled": true,
        "tags": [],
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "snlo4gpSJgtl",
        "outputId": "dae93632-5d10-479e-d246-5046a064dea6"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Encoder(\n",
              "  (embedding): Embedding(197728, 512)\n",
              "  (pos_embedding): Embedding(200, 512)\n",
              "  (encoder): TransformerEncoder(\n",
              "    (layers): ModuleList(\n",
              "      (0-4): 5 x TransformerEncoderLayer(\n",
              "        (self_attn): MultiheadAttention(\n",
              "          (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)\n",
              "        )\n",
              "        (linear1): Linear(in_features=512, out_features=2048, bias=True)\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "        (linear2): Linear(in_features=2048, out_features=512, bias=True)\n",
              "        (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
              "        (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
              "        (dropout1): Dropout(p=0.1, inplace=False)\n",
              "        (dropout2): Dropout(p=0.1, inplace=False)\n",
              "      )\n",
              "    )\n",
              "    (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ],
      "source": [
        "trans_encoder = Encoder(vocab_size=vocab_size, embed_dim=512, hidden_size=512, nhead=8, num_layers=5, max_position=200)\n",
        "trans_encoder.cuda()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2.1 Set the related parameters before training"
      ],
      "metadata": {
        "id": "esSrDNH-oMX2"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "scrolled": true,
        "tags": [],
        "id": "jp_5EAC_Jgtm"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import torch.optim as optim\n",
        "torch.manual_seed(90042)\n",
        "torch.cuda.manual_seed_all(90042)\n",
        "random.seed(90042)\n",
        "# setting the optimizer for encoder\n",
        "encoder_optimizer = optim.Adam(trans_encoder.parameters())\n",
        "# setting the max learning rate\n",
        "max_lr = 1e-2\n",
        "for param_group in encoder_optimizer.param_groups:\n",
        "    param_group['lr'] = max_lr\n",
        "\n",
        "save_dir = \"model_ckpts\"\n",
        "if not os.path.exists(save_dir):\n",
        "    os.makedirs(save_dir)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nzskT0YnJgtm"
      },
      "source": [
        "### 2.2 Training and validation preparation"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Validation functions: The functions in this part are used during the training to evaluate the current encoder on dev dataset."
      ],
      "metadata": {
        "id": "dvniBk76E8D_"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "tags": [],
        "id": "8b-ADBbsJgtm"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn.functional as F\n",
        "from tqdm import tqdm\n",
        "import numpy as np\n",
        "\n",
        "def get_embeddings(text_idx, model, text_len):\n",
        "    \"\"\"\n",
        "    Generate embeddings for texts using the provided encoder model.\n",
        "\n",
        "    Args:\n",
        "    text_idx (list): List of text indices to be embedded.\n",
        "    model (torch.nn.Module): Encoder model to generate embeddings.\n",
        "    text_len (int): Fixed length of the text inputs.\n",
        "\n",
        "    Returns:\n",
        "    torch.Tensor: Normalized embeddings of the input texts.\n",
        "    \"\"\"\n",
        "    model.eval()\n",
        "    embeddings = []\n",
        "    batch_size = 1000\n",
        "\n",
        "    # Process text indices in batches without tqdm\n",
        "    for start_idx in range(0, len(text_idx), batch_size):\n",
        "        end_idx = min(start_idx + batch_size, len(text_idx))\n",
        "        cur_text = torch.LongTensor(text_idx[start_idx:end_idx]).view(-1, text_len).cuda()\n",
        "        cur_text_pos = torch.LongTensor([list(range(text_len)) for _ in range(end_idx - start_idx)]).cuda()\n",
        "\n",
        "        # Generate embeddings\n",
        "        embedding = model(cur_text, cur_text_pos)\n",
        "        embedding = embedding[:, 0, :].detach()\n",
        "        normalized_embedding = F.normalize(embedding, p=2, dim=1).cpu()\n",
        "        del embedding, cur_text, cur_text_pos\n",
        "        embeddings.append(normalized_embedding)\n",
        "\n",
        "    return torch.cat(embeddings, dim=0)\n",
        "\n",
        "def calculate_fscore(claim_embeddings, evidence_embeddings, dev_sort_potential_evidences, dev_evidences, dev_candis_num, retrieval_num):\n",
        "    \"\"\"\n",
        "    Calculate the F-score for evidence retrieval.\n",
        "\n",
        "    Args:\n",
        "    claim_embeddings (torch.Tensor): claim embeddings.\n",
        "    evidence_embeddings (torch.Tensor): Evidence embeddings.\n",
        "    dev_sort_potential_evidences (list): Sorted potential evidences.\n",
        "    dev_evidences (list): Actual evidences.\n",
        "    dev_candis_num (int): Number of candidate evidences considered.\n",
        "    retrieval_num (int): Number of retrieved evidences for evaluation.\n",
        "\n",
        "    Returns:\n",
        "    float: The average F-score.\n",
        "    \"\"\"\n",
        "    fscores = []\n",
        "    batch_size = 1000\n",
        "\n",
        "    # Evaluate F-score in batches\n",
        "    for start_idx in tqdm(range(0, len(claim_embeddings), batch_size), desc=\"Calculating F-scores\"):\n",
        "        end_idx = min(start_idx + batch_size, len(claim_embeddings))\n",
        "        scores = torch.mm(claim_embeddings[start_idx:end_idx], evidence_embeddings.t())\n",
        "\n",
        "        for i in range(scores.size(0)):\n",
        "            current_scores = torch.index_select(scores[i], 0, torch.LongTensor(dev_sort_potential_evidences[start_idx+i][:dev_candis_num]))\n",
        "            topk_ids = torch.argsort(current_scores).tolist()\n",
        "            select_ids = topk_ids[:retrieval_num]\n",
        "\n",
        "            pred_evidences = [dev_sort_potential_evidences[start_idx+i][j] for j in select_ids]\n",
        "            label = dev_evidences[start_idx+i]\n",
        "            evidence_correct = sum(1 for eid in label if eid in pred_evidences)\n",
        "\n",
        "            if evidence_correct > 0:\n",
        "                recall = evidence_correct / len(label)\n",
        "                precision = evidence_correct / retrieval_num\n",
        "                fscores.append(2 * precision * recall / (precision + recall))\n",
        "            else:\n",
        "                fscores.append(0)\n",
        "\n",
        "    return np.mean(fscores)\n",
        "\n",
        "def validate(dev_claim_text_idx, evidence_text_idx, dev_sort_potential_evidences, dev_evidences, encoder_model,\n",
        "             dev_candis_num = 10, retrieval_num = 5, pre_computed_evidence_embeddings=None):\n",
        "    \"\"\"\n",
        "    Validate the encoder model by computing the F-score for evidence retrieval.\n",
        "\n",
        "    Args:\n",
        "    dev_claim_text_idx (list): Development claim text indices.\n",
        "    evidence_text_idx (list): Evidence text indices.\n",
        "    dev_sort_potential_evidences (list): Sorted potential evidences.\n",
        "    dev_evidences (list): Actually relevant evidences.\n",
        "    encoder_model (torch.nn.Module): Encoder model to use for embeddings.\n",
        "    pre_computed_evidence_embeddings: Pre-computed evidence embeddings.\n",
        "\n",
        "    Returns:\n",
        "    float: The F-score of evidence retrieval.\n",
        "    \"\"\"\n",
        "    encoder_model.eval()\n",
        "    # Get embeddings for evidences and claims\n",
        "    if pre_computed_evidence_embeddings is None:\n",
        "      evidence_embeddings = get_embeddings(evidence_text_idx, encoder_model, len(evidence_text_idx[0]))\n",
        "    else:\n",
        "      evidence_embeddings = pre_computed_evidence_embeddings\n",
        "    claim_query_embeddings = get_embeddings(dev_claim_text_idx, encoder_model, len(dev_claim_text_idx[0]))\n",
        "\n",
        "    # Calculate F-score for evidence retrieval\n",
        "    fscore = calculate_fscore(claim_query_embeddings, evidence_embeddings, dev_sort_potential_evidences, dev_evidences, dev_candis_num, retrieval_num)\n",
        "\n",
        "    print(\"Evidence Retrieval F-score: {:.3f}\\n\".format(fscore))\n",
        "\n",
        "    return fscore\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Training starts here. We first define some functions for this training and then use them to train our encoder."
      ],
      "metadata": {
        "id": "x2OiGEsYFjeh"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Define loss function which compute the mean value of probabilities of positive evidences.\n",
        "\n",
        "\n",
        "The model learns to increase the scores (and thus the probabilities) of positive evidences while decreasing those of negative ones."
      ],
      "metadata": {
        "id": "d8l6itn1QFLB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def compute_loss(claim_embeddings, evidence_embeddings, positive_evidences):\n",
        "    \"\"\"\n",
        "    Compute the training loss given the embeddings and positive evidence indices.\n",
        "    \"\"\"\n",
        "    cos_sims = torch.mm(claim_embeddings, evidence_embeddings.t())\n",
        "    # softmax turn the similarity into probabilities\n",
        "    scores = - torch.nn.functional.log_softmax(cos_sims / 0.1, dim=1)\n",
        "    # the loss we use is the mean value of probabilities of positive evidences.\n",
        "    losses = [torch.mean(torch.index_select(scores[i], 0, torch.LongTensor(positive_evidences[i]).cuda())) for i in range(len(positive_evidences))]\n",
        "    return torch.stack(losses).mean()"
      ],
      "metadata": {
        "id": "-TrjumGBQFcp"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Here are two auxilary functions used in the training function."
      ],
      "metadata": {
        "id": "xn8xJbO4Q4KN"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "scrolled": true,
        "tags": [],
        "id": "HaIzwah5Jgtn"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.cuda.amp import GradScaler, autocast\n",
        "from tqdm import tqdm\n",
        "\n",
        "def adjust_learning_rate(optimizer, step_cnt, warmup_steps, max_lr):\n",
        "    \"\"\"\n",
        "    Adjust the learning rate based on the current step count.\n",
        "    Args:\n",
        "    optimizer (torch.optim.Optimizer): The optimizer for which to adjust the learning rate.\n",
        "    step_cnt (int): The current step count in the training process.\n",
        "    warmup_steps (int): The number of steps to linearly increase the learning rate.\n",
        "    max_lr (float): The maximum learning rate after warmup.\n",
        "    \"\"\"\n",
        "    if step_cnt <= warmup_steps:\n",
        "        lr = step_cnt * (max_lr - 1e-8) / warmup_steps + 1e-8\n",
        "    else:\n",
        "        lr = max_lr - (step_cnt - warmup_steps) * 1e-5\n",
        "\n",
        "    for param_group in optimizer.param_groups:\n",
        "        param_group['lr'] = lr\n",
        "    return lr\n",
        "\n",
        "def perform_model_forward_pass(model, batch):\n",
        "    \"\"\"\n",
        "    Perform the forward pass for the model.\n",
        "    \"\"\"\n",
        "    model.train()\n",
        "    claim_query_embeddings = model(batch[\"claim_queries\"].cuda(), batch[\"claim_queries_pos\"].cuda())\n",
        "    evidence_embeddings = model(batch[\"batch_evidences\"].cuda(), batch[\"batch_evidences_pos\"].cuda())\n",
        "    claim_query_embeddings = torch.nn.functional.normalize(claim_query_embeddings[:, 0, :], p=2, dim=1)\n",
        "    evidence_embeddings = torch.nn.functional.normalize(evidence_embeddings[:, 0, :], p=2, dim=1)\n",
        "    return claim_query_embeddings, evidence_embeddings\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The training function."
      ],
      "metadata": {
        "id": "sACFG3cvQ0aZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def train_model(model, dataloader, optimizer, epochs, accumulate_step, grad_norm, warmup_steps, report_freq, eval_interval, save_dir):\n",
        "    \"\"\"\n",
        "    Train the model using the provided data loader and optimizer according to the given parameters.\n",
        "    Args:\n",
        "    model (torch.nn.Module): The model to train.\n",
        "    dataloader (torch.utils.data.DataLoader): The DataLoader for providing training data.\n",
        "    optimizer (torch.optim.Optimizer): The optimizer to use for training.\n",
        "    epochs (int): Total number of epochs to train.\n",
        "    accumulate_step (int): Steps to accumulate gradients before performing an update.\n",
        "    grad_norm (float): Max norm for gradient clipping.\n",
        "    warmup_steps (int): Number of warm-up steps for learning rate adjustment.\n",
        "    report_freq (int): Frequency of reporting training statistics.\n",
        "    eval_interval (int): Interval to perform validation checks.\n",
        "    save_dir (str): Directory to save model checkpoints.\n",
        "    \"\"\"\n",
        "    scaler = GradScaler()\n",
        "    step_cnt = 0\n",
        "    all_step_cnt = 0\n",
        "    avg_loss = 0\n",
        "    maximum_f_score = 0\n",
        "\n",
        "    if not os.path.exists(save_dir):\n",
        "        os.makedirs(save_dir)\n",
        "\n",
        "    for epoch in range(epochs):\n",
        "        epoch_step = 0\n",
        "\n",
        "        for batch in tqdm(dataloader, desc=f\"Epoch {epoch + 1}\"):\n",
        "            step_cnt += 1\n",
        "            with autocast():\n",
        "                # Forward pass to get embeddings of claims and evidences and then compute loss\n",
        "                claim_query_embeddings, evidence_embeddings = perform_model_forward_pass(model, batch)\n",
        "                loss = compute_loss(claim_query_embeddings, evidence_embeddings, batch[\"positive_evidences\"])\n",
        "                loss = loss / accumulate_step\n",
        "            # Backward pass\n",
        "            scaler.scale(loss).backward()\n",
        "            avg_loss += loss.item()\n",
        "\n",
        "            if step_cnt == accumulate_step:\n",
        "                # Gradient clipping and optimizer step\n",
        "                if grad_norm > 0:\n",
        "                    nn.utils.clip_grad_norm_(model.parameters(), grad_norm)\n",
        "\n",
        "                scaler.step(optimizer)\n",
        "                scaler.update()\n",
        "                optimizer.zero_grad()\n",
        "\n",
        "                # Learning rate adjustment\n",
        "                lr = adjust_learning_rate(optimizer, all_step_cnt, warmup_steps, max_lr)\n",
        "\n",
        "                step_cnt = 0\n",
        "                epoch_step += 1\n",
        "                all_step_cnt += 1\n",
        "\n",
        "                # Report training status\n",
        "                if all_step_cnt % report_freq == 0:\n",
        "                    print(f\"\\nEpoch: {epoch + 1}, Step: {epoch_step}, Avg Loss: {avg_loss / report_freq:.6f}, Learning Rate: {lr:.6f}\\n\")\n",
        "                    avg_loss = 0\n",
        "\n",
        "                # Evaluation and checkpointing\n",
        "                if all_step_cnt % eval_interval == 0 and all_step_cnt != 0:\n",
        "                    f_score = validate(dev_claim_input, evidences_input, dev_sort_potential_evidences, dev_evidences, model)\n",
        "                    # turn back the model to train mode after evaluation\n",
        "                    model.train()\n",
        "                    if f_score > maximum_f_score:\n",
        "                        maximum_f_score = f_score\n",
        "                        torch.save(model.state_dict(), os.path.join(save_dir, \"best_ckpt.bin\"))\n",
        "                        print(f\"New best F-score: {f_score:.4f} at Epoch: {epoch + 1}, Step: {epoch_step}\")\n",
        "\n",
        "            # Clean up to save memory\n",
        "            del loss, claim_query_embeddings, evidence_embeddings"
      ],
      "metadata": {
        "id": "rbFIMEM0QzUu"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2.3 Training start here!"
      ],
      "metadata": {
        "id": "N4nTqfSNtMyc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_model(trans_encoder, dataloader, encoder_optimizer, epochs=5, accumulate_step=2, grad_norm=4,\n",
        "            warmup_steps=200, report_freq=15, eval_interval=50, save_dir=\"model_ckpts\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1YIjbZhOHU0c",
        "outputId": "cafab381-89f6-40a9-c0cc-7714b0a670dc"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 1:   9%|▉         | 22/246 [00:04<00:21, 10.58it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch: 1, Step: 10, Avg Loss: 4.191335, Learning Rate: 0.000450\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 1:  17%|█▋        | 42/246 [00:06<00:17, 11.37it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch: 1, Step: 20, Avg Loss: 4.211146, Learning Rate: 0.000950\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 1:  25%|██▌       | 62/246 [00:07<00:16, 11.14it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch: 1, Step: 30, Avg Loss: 4.197593, Learning Rate: 0.001450\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 1:  33%|███▎      | 82/246 [00:09<00:14, 11.24it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch: 1, Step: 40, Avg Loss: 4.193512, Learning Rate: 0.001950\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 1:  40%|███▉      | 98/246 [00:10<00:12, 11.39it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch: 1, Step: 50, Avg Loss: 4.183458, Learning Rate: 0.002450\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 1:  40%|███▉      | 98/246 [00:30<00:12, 11.39it/s]\n",
            "Calculating F-scores:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Calculating F-scores: 100%|██████████| 1/1 [00:02<00:00,  2.43s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Evidence Retrieval F-score: 0.072\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 1:  41%|████      | 101/246 [14:54<4:23:53, 109.20s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "New best F-score: 0.0724 at Epoch: 1, Step: 50\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 1:  49%|████▉     | 121/246 [14:56<05:40,  2.72s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch: 1, Step: 60, Avg Loss: 4.161486, Learning Rate: 0.002950\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 1:  57%|█████▋    | 141/246 [14:58<00:17,  6.07it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch: 1, Step: 70, Avg Loss: 4.194533, Learning Rate: 0.003450\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 1:  65%|██████▌   | 161/246 [15:00<00:08, 10.51it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch: 1, Step: 80, Avg Loss: 4.223937, Learning Rate: 0.003950\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 1:  74%|███████▎  | 181/246 [15:01<00:05, 10.86it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch: 1, Step: 90, Avg Loss: 4.210349, Learning Rate: 0.004450\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 1:  81%|████████  | 199/246 [15:03<00:04, 10.93it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch: 1, Step: 100, Avg Loss: 4.204441, Learning Rate: 0.004950\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 1:  81%|████████  | 199/246 [15:20<00:04, 10.93it/s]\n",
            "Calculating F-scores:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Calculating F-scores: 100%|██████████| 1/1 [00:02<00:00,  2.37s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Evidence Retrieval F-score: 0.073\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 1:  82%|████████▏ | 201/246 [29:59<1:34:44, 126.33s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "New best F-score: 0.0729 at Epoch: 1, Step: 100\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 1:  90%|████████▉ | 221/246 [30:01<01:09,  2.77s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch: 1, Step: 110, Avg Loss: 4.216748, Learning Rate: 0.005450\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 1:  98%|█████████▊| 241/246 [30:03<00:00,  5.83it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch: 1, Step: 120, Avg Loss: 4.217640, Learning Rate: 0.005950\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 1: 100%|██████████| 246/246 [30:03<00:00,  7.33s/it]\n",
            "Epoch 2:   6%|▌         | 15/246 [00:01<00:21, 10.91it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch: 2, Step: 7, Avg Loss: 4.177513, Learning Rate: 0.006450\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 2:  14%|█▍        | 35/246 [00:03<00:18, 11.12it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch: 2, Step: 17, Avg Loss: 4.172003, Learning Rate: 0.006950\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 2:  22%|██▏       | 53/246 [00:04<00:17, 10.87it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch: 2, Step: 27, Avg Loss: 4.188939, Learning Rate: 0.007450\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 2:  22%|██▏       | 53/246 [00:16<00:17, 10.87it/s]\n",
            "Calculating F-scores:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Calculating F-scores: 100%|██████████| 1/1 [00:02<00:00,  2.91s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Evidence Retrieval F-score: 0.092\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 2:  22%|██▏       | 54/246 [14:59<8:25:35, 158.00s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "New best F-score: 0.0918 at Epoch: 2, Step: 27\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 2:  31%|███       | 76/246 [15:01<07:47,  2.75s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch: 2, Step: 37, Avg Loss: 4.206278, Learning Rate: 0.007950\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 2:  39%|███▉      | 96/246 [15:03<00:24,  6.03it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch: 2, Step: 47, Avg Loss: 4.228678, Learning Rate: 0.008450\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 2:  47%|████▋     | 116/246 [15:05<00:12, 10.37it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch: 2, Step: 57, Avg Loss: 4.213851, Learning Rate: 0.008950\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 2:  55%|█████▌    | 136/246 [15:07<00:10, 10.80it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch: 2, Step: 67, Avg Loss: 4.219225, Learning Rate: 0.009450\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 2:  62%|██████▏   | 152/246 [15:08<00:08, 11.24it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch: 2, Step: 77, Avg Loss: 4.173221, Learning Rate: 0.009950\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 2:  62%|██████▏   | 152/246 [15:26<00:08, 11.24it/s]\n",
            "Calculating F-scores:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Calculating F-scores: 100%|██████████| 1/1 [00:03<00:00,  3.84s/it]\n",
            "Epoch 2:  63%|██████▎   | 154/246 [29:55<3:24:08, 133.14s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Evidence Retrieval F-score: 0.080\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 2:  72%|███████▏  | 176/246 [29:58<02:16,  1.95s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch: 2, Step: 87, Avg Loss: 4.185212, Learning Rate: 0.009910\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 2:  80%|███████▉  | 196/246 [30:00<00:07,  6.85it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch: 2, Step: 97, Avg Loss: 4.204511, Learning Rate: 0.009810\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 2:  88%|████████▊ | 216/246 [30:02<00:02, 10.79it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch: 2, Step: 107, Avg Loss: 4.202397, Learning Rate: 0.009710\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 2:  96%|█████████▌| 236/246 [30:03<00:00, 10.94it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch: 2, Step: 117, Avg Loss: 4.222156, Learning Rate: 0.009610\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 2: 100%|██████████| 246/246 [30:05<00:00,  7.34s/it]\n",
            "Epoch 3:   3%|▎         | 7/246 [00:00<00:26,  9.14it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch: 3, Step: 4, Avg Loss: 4.169816, Learning Rate: 0.009510\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Calculating F-scores:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Calculating F-scores: 100%|██████████| 1/1 [00:02<00:00,  2.80s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Evidence Retrieval F-score: 0.085\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 3:  12%|█▏        | 30/246 [14:48<07:01,  1.95s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch: 3, Step: 14, Avg Loss: 4.165401, Learning Rate: 0.009410\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 3:  20%|██        | 50/246 [14:50<00:27,  7.08it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch: 3, Step: 24, Avg Loss: 4.187390, Learning Rate: 0.009310\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 3:  28%|██▊       | 70/246 [14:52<00:15, 11.11it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch: 3, Step: 34, Avg Loss: 4.198667, Learning Rate: 0.009210\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 3:  37%|███▋      | 90/246 [14:54<00:14, 11.09it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch: 3, Step: 44, Avg Loss: 4.190304, Learning Rate: 0.009110\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 3:  43%|████▎     | 106/246 [14:55<00:12, 11.11it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch: 3, Step: 54, Avg Loss: 4.212715, Learning Rate: 0.009010\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 3:  43%|████▎     | 106/246 [15:11<00:12, 11.11it/s]\n",
            "Calculating F-scores:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Calculating F-scores: 100%|██████████| 1/1 [00:02<00:00,  2.93s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Evidence Retrieval F-score: 0.074\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 3:  52%|█████▏    | 129/246 [29:41<05:18,  2.72s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch: 3, Step: 64, Avg Loss: 4.192585, Learning Rate: 0.008910\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 3:  61%|██████    | 149/246 [29:43<00:16,  5.99it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch: 3, Step: 74, Avg Loss: 4.197869, Learning Rate: 0.008810\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 3:  69%|██████▊   | 169/246 [29:45<00:07, 10.68it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch: 3, Step: 84, Avg Loss: 4.197557, Learning Rate: 0.008710\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 3:  77%|███████▋  | 189/246 [29:47<00:05, 11.01it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch: 3, Step: 94, Avg Loss: 4.201171, Learning Rate: 0.008610\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 3:  84%|████████▍ | 207/246 [29:49<00:03, 11.03it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch: 3, Step: 104, Avg Loss: 4.204408, Learning Rate: 0.008510\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 3:  84%|████████▍ | 207/246 [30:01<00:03, 11.03it/s]\n",
            "Calculating F-scores:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Calculating F-scores: 100%|██████████| 1/1 [00:02<00:00,  2.71s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Evidence Retrieval F-score: 0.090\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 3:  93%|█████████▎| 229/246 [44:34<00:46,  2.73s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch: 3, Step: 114, Avg Loss: 4.210955, Learning Rate: 0.008410\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 3: 100%|██████████| 246/246 [44:36<00:00, 10.88s/it]\n",
            "Epoch 4:   1%|          | 3/246 [00:00<00:27,  8.69it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch: 4, Step: 1, Avg Loss: 4.187757, Learning Rate: 0.008310\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 4:   9%|▉         | 23/246 [00:02<00:20, 11.06it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch: 4, Step: 11, Avg Loss: 4.183949, Learning Rate: 0.008210\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 4:  17%|█▋        | 43/246 [00:04<00:18, 10.98it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch: 4, Step: 21, Avg Loss: 4.198098, Learning Rate: 0.008110\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 4:  25%|██▍       | 61/246 [00:05<00:17, 10.80it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch: 4, Step: 31, Avg Loss: 4.191273, Learning Rate: 0.008010\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 4:  25%|██▍       | 61/246 [00:24<00:17, 10.80it/s]\n",
            "Calculating F-scores:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Calculating F-scores: 100%|██████████| 1/1 [00:03<00:00,  3.69s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Evidence Retrieval F-score: 0.095\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 4:  26%|██▌       | 63/246 [15:08<6:28:18, 127.32s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "New best F-score: 0.0953 at Epoch: 4, Step: 31\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 4:  34%|███▎      | 83/246 [15:10<07:34,  2.79s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch: 4, Step: 41, Avg Loss: 4.174054, Learning Rate: 0.007910\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 4:  42%|████▏     | 103/246 [15:12<00:23,  5.98it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch: 4, Step: 51, Avg Loss: 4.195454, Learning Rate: 0.007810\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 4:  50%|█████     | 123/246 [15:14<00:12, 10.09it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch: 4, Step: 61, Avg Loss: 4.191637, Learning Rate: 0.007710\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 4:  58%|█████▊    | 143/246 [15:16<00:09, 10.39it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch: 4, Step: 71, Avg Loss: 4.208059, Learning Rate: 0.007610\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 4:  65%|██████▌   | 161/246 [15:17<00:07, 10.83it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch: 4, Step: 81, Avg Loss: 4.197741, Learning Rate: 0.007510\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 4:  65%|██████▌   | 161/246 [15:34<00:07, 10.83it/s]\n",
            "Calculating F-scores:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Calculating F-scores: 100%|██████████| 1/1 [00:02<00:00,  2.71s/it]\n",
            "Epoch 4:  66%|██████▌   | 162/246 [30:01<3:38:25, 156.02s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Evidence Retrieval F-score: 0.076\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 4:  75%|███████▍  | 184/246 [30:03<02:48,  2.72s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch: 4, Step: 91, Avg Loss: 4.210366, Learning Rate: 0.007410\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 4:  83%|████████▎ | 204/246 [30:05<00:07,  5.97it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch: 4, Step: 101, Avg Loss: 4.203722, Learning Rate: 0.007310\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 4:  91%|█████████ | 224/246 [30:07<00:02, 10.60it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch: 4, Step: 111, Avg Loss: 4.182894, Learning Rate: 0.007210\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 4:  99%|█████████▉| 244/246 [30:09<00:00, 11.15it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch: 4, Step: 121, Avg Loss: 4.179206, Learning Rate: 0.007110\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 4: 100%|██████████| 246/246 [30:09<00:00,  7.36s/it]\n",
            "Epoch 5:   6%|▌         | 15/246 [00:01<00:21, 10.76it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch: 5, Step: 8, Avg Loss: 4.174708, Learning Rate: 0.007010\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 5:   6%|▌         | 15/246 [00:15<00:21, 10.76it/s]\n",
            "Calculating F-scores:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Calculating F-scores: 100%|██████████| 1/1 [00:02<00:00,  2.32s/it]\n",
            "Epoch 5:   7%|▋         | 16/246 [14:43<10:33:32, 165.27s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Evidence Retrieval F-score: 0.079\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 5:  15%|█▌        | 38/246 [14:45<09:25,  2.72s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch: 5, Step: 18, Avg Loss: 4.203152, Learning Rate: 0.006910\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 5:  24%|██▎       | 58/246 [14:47<00:30,  6.10it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch: 5, Step: 28, Avg Loss: 4.190424, Learning Rate: 0.006810\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 5:  32%|███▏      | 78/246 [14:49<00:16, 10.47it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch: 5, Step: 38, Avg Loss: 4.211583, Learning Rate: 0.006710\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 5:  40%|███▉      | 98/246 [14:51<00:13, 10.89it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch: 5, Step: 48, Avg Loss: 4.176031, Learning Rate: 0.006610\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 5:  46%|████▋     | 114/246 [14:52<00:12, 10.93it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch: 5, Step: 58, Avg Loss: 4.207781, Learning Rate: 0.006510\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 5:  46%|████▋     | 114/246 [15:05<00:12, 10.93it/s]\n",
            "Calculating F-scores:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Calculating F-scores: 100%|██████████| 1/1 [00:02<00:00,  2.32s/it]\n",
            "Epoch 5:  47%|████▋     | 116/246 [29:33<4:46:28, 132.22s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Evidence Retrieval F-score: 0.075\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 5:  56%|█████▌    | 138/246 [29:35<04:51,  2.70s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch: 5, Step: 68, Avg Loss: 4.178936, Learning Rate: 0.006410\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 5:  64%|██████▍   | 158/246 [29:37<00:14,  6.07it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch: 5, Step: 78, Avg Loss: 4.192685, Learning Rate: 0.006310\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 5:  72%|███████▏  | 178/246 [29:39<00:06, 10.88it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch: 5, Step: 88, Avg Loss: 4.196143, Learning Rate: 0.006210\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 5:  80%|████████  | 198/246 [29:41<00:04, 10.71it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch: 5, Step: 98, Avg Loss: 4.201349, Learning Rate: 0.006110\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 5:  87%|████████▋ | 214/246 [29:42<00:02, 10.83it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch: 5, Step: 108, Avg Loss: 4.190344, Learning Rate: 0.006010\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 5:  87%|████████▋ | 214/246 [29:55<00:02, 10.83it/s]\n",
            "Calculating F-scores:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Calculating F-scores: 100%|██████████| 1/1 [00:02<00:00,  2.35s/it]\n",
            "Epoch 5:  88%|████████▊ | 216/246 [44:26<1:06:17, 132.59s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Evidence Retrieval F-score: 0.087\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 5:  97%|█████████▋| 238/246 [44:28<00:21,  2.71s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch: 5, Step: 118, Avg Loss: 4.206174, Learning Rate: 0.005910\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 5: 100%|██████████| 246/246 [44:29<00:00, 10.85s/it]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EzGuzHPE87Ya"
      },
      "source": [
        "# 3.Testing and Evaluation\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 3.1 Pre-compute Evidence embeddings"
      ],
      "metadata": {
        "id": "jvGcGAgSzi8X"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Load the best check point that we got from the training"
      ],
      "metadata": {
        "id": "2qp9k9jQjq5L"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "tags": [],
        "id": "9NX4h_LGJgtn",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a732c3af-e784-46d3-f937-798636d44481"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Encoder(\n",
              "  (embedding): Embedding(197728, 512)\n",
              "  (pos_embedding): Embedding(200, 512)\n",
              "  (encoder): TransformerEncoder(\n",
              "    (layers): ModuleList(\n",
              "      (0-4): 5 x TransformerEncoderLayer(\n",
              "        (self_attn): MultiheadAttention(\n",
              "          (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)\n",
              "        )\n",
              "        (linear1): Linear(in_features=512, out_features=2048, bias=True)\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "        (linear2): Linear(in_features=2048, out_features=512, bias=True)\n",
              "        (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
              "        (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
              "        (dropout1): Dropout(p=0.1, inplace=False)\n",
              "        (dropout2): Dropout(p=0.1, inplace=False)\n",
              "      )\n",
              "    )\n",
              "    (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 31
        }
      ],
      "source": [
        "import os\n",
        "trans_encoder.load_state_dict(torch.load(os.path.join(save_dir, \"best_ckpt.bin\")))\n",
        "\n",
        "trans_encoder.cuda()\n",
        "trans_encoder.eval()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now to make prediction and evaluation, we need to encode all evidences using the trained encoder for later prediction on dev and test dataset."
      ],
      "metadata": {
        "id": "kpoMB5Q6maoI"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "tags": [],
        "id": "r22jehcVJgto"
      },
      "outputs": [],
      "source": [
        "evidence_embeddings = []\n",
        "evidence_embeddings = get_embeddings(evidences_input, trans_encoder, len(evidences_input[0]))"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 3.2 Evaluate on dev dataset"
      ],
      "metadata": {
        "id": "aMS5pbQxz1QH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Use the validate function that we have defined in the training part to evaluate our trained model on dev dataset."
      ],
      "metadata": {
        "id": "cFIeQVFPo_Nn"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "scrolled": true,
        "tags": [],
        "id": "Io0F8kZlJgto",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "de10577f-8e4b-4a28-a475-001682b75643"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Calculating F-scores: 100%|██████████| 1/1 [00:02<00:00,  2.82s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Evidence Retrieval F-score: 0.102\n",
            "\n",
            "0.10166975881261596\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "fscore = validate(dev_claim_input, evidences_input, dev_sort_potential_evidences, dev_evidences, trans_encoder,\n",
        "                  dev_candis_num=8, retrieval_num=5, pre_computed_evidence_embeddings=evidence_embeddings)\n",
        "print(fscore)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 3.3 Retrieve the relevant evidences for test dataset"
      ],
      "metadata": {
        "id": "gkr8Qb9k0QeY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "We then define a function for predicting the retrieved relevant evidences."
      ],
      "metadata": {
        "id": "8nrghuV9z50X"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "id": "6ZVeNYIH9IaL",
        "tags": []
      },
      "outputs": [],
      "source": [
        "def evidence_predicts(dev_text_idx, evidences_embeddings, dev_sort_evidences, evidences_ids, encoder_model, dev_candis_num, retrieval_num, batch_size=100):\n",
        "    \"\"\"\n",
        "    Predict the most relevant evidences for a set of development texts using batch processing.\n",
        "\n",
        "    Args:\n",
        "    dev_text_idx (list of list of int): Development text indices for queries.\n",
        "    evidences_embeddings (torch.Tensor): Pre-computed embeddings for all possible evidences.\n",
        "    dev_sort_evidences (list of list of int): Sorted indices of potential evidences for each claim, based on TFIDF.\n",
        "    evidences_ids (list): List of original IDs corresponding to the evidences.\n",
        "    encoder_model (torch.nn.Module): Model to generate embeddings for the queries.\n",
        "    dev_candis_num (int): Number of candidate evidences to consider for final ranking.\n",
        "    retrieval_num (int): Number of top evidences to retrieve.\n",
        "    batch_size (int): The size of each batch to process.\n",
        "\n",
        "    Returns:\n",
        "    list of list: A list containing the lists of predicted evidence IDs for each development text.\n",
        "    \"\"\"\n",
        "    encoder_model.eval()\n",
        "    text_len = len(dev_text_idx[0])\n",
        "    preds = []\n",
        "\n",
        "    # Processing in batches to manage memory consumption\n",
        "    for start_idx in range(0, len(dev_text_idx), batch_size):\n",
        "        end_idx = min(start_idx + batch_size, len(dev_text_idx))\n",
        "\n",
        "        # Generate embeddings for the current batch of queries\n",
        "        batch_text_idx = dev_text_idx[start_idx:end_idx]\n",
        "        claim_embeddings = get_embeddings(batch_text_idx, encoder_model, text_len)\n",
        "\n",
        "        # Compute cosine similarity scores between batch query embeddings and all evidence embeddings\n",
        "        scores = torch.mm(claim_embeddings, evidences_embeddings.t())\n",
        "\n",
        "        # Determine the top evidences based on the scores for each query in the batch\n",
        "        for i in range(scores.size(0)):\n",
        "            # Select top candidate evidences scores\n",
        "            candidate_scores = torch.index_select(scores[i], 0, torch.LongTensor(dev_sort_evidences[start_idx + i][:dev_candis_num]))\n",
        "            topk_ids = torch.argsort(candidate_scores, descending=True).tolist()\n",
        "            select_ids = topk_ids[:retrieval_num]\n",
        "\n",
        "            # Map back to original evidence IDs\n",
        "            pred_evidences = [evidences_ids[j] for j in select_ids]\n",
        "            preds.append(pred_evidences)\n",
        "\n",
        "    return preds"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Use this function to get the retrieved evidences for dev and test dataset."
      ],
      "metadata": {
        "id": "DJyo6P2t0IGd"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "tags": [],
        "id": "gC7-ASGYJgtp"
      },
      "outputs": [],
      "source": [
        "dev_evidences_ids_predicted = evidence_predicts(dev_claim_input, evidence_embeddings, dev_sort_potential_evidences, evidences_ids,\n",
        "                                                trans_encoder,dev_candis_num=10,retrieval_num=5)\n",
        "test_evidences_ids_predicted = evidence_predicts(test_claim_input, evidence_embeddings, test_sort_potential_evidences, evidences_ids,\n",
        "                                                 trans_encoder,dev_candis_num=10,retrieval_num=5)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Store the predictions into the dictionary for dev and test claims"
      ],
      "metadata": {
        "id": "vqphRzhxzHr5"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "tags": [],
        "id": "c4PcvpfmJgtp"
      },
      "outputs": [],
      "source": [
        "dev_claims = json.load(open(\"data/dev-claims.json\", \"r\"))\n",
        "test_claims = json.load(open(\"data/test-claims-unlabelled.json\", \"r\"))\n",
        "\n",
        "def store_predictions(claims_data, ids, predicted_evidences_ids):\n",
        "    \"\"\"\n",
        "    Populate a dictionary with claims data where each claim is updated with associated evidence IDs.\n",
        "\n",
        "    Args:\n",
        "    claims_data (dict): Dictionary of claims.\n",
        "    ids (list): List of claim IDs.\n",
        "    evidences_ids (list of list of int): List of evidence IDs for each claim.\n",
        "\n",
        "    Returns:\n",
        "    dict: A dictionary with updated claims including their associated evidences.\n",
        "    \"\"\"\n",
        "    predictions = {}\n",
        "    for idx, evidence_ids in enumerate(predicted_evidences_ids):\n",
        "\n",
        "        cur_data = claims_data[ids[idx]].copy()  # Use copy to avoid modifying the original data\n",
        "        cur_data['evidences'] = evidence_ids\n",
        "        predictions[ids[idx]] = cur_data\n",
        "    return predictions\n",
        "\n",
        "pred_dev_claims = store_predictions(dev_claims, dev_ids, dev_evidences_ids_predicted)\n",
        "pred_test_claims = store_predictions(test_claims, test_ids, test_evidences_ids_predicted)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Store the prediction result for evidence retrieval as a json file"
      ],
      "metadata": {
        "id": "EpaLW1AazXpj"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "tags": [],
        "id": "A-RuELZvJgtp"
      },
      "outputs": [],
      "source": [
        "json.dump(pred_dev_claims, open(\"pred_dev_claims_retrieval.json\", \"w\"))\n",
        "json.dump(pred_test_claims, open(\"pred_test_claims_retrieval.json\", \"w\"))"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 3.4 Preparation for Claim Classification"
      ],
      "metadata": {
        "id": "u9Q1Jq8G0iBn"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "At the last of evidence retrieval, we also need to retrieve the relevant evidences for training dataset fot the next part ---- Claim Classification.\n",
        "\n",
        "We will need to use the retrieved evidences and the claim together to train our next claim classification model.\n",
        "\n",
        "Here, we only keep the wrongly predicted relevant evidences. We will use the truly relevant evidences for training claim classification but also include some of these wrongly predicted relevant evidences as we will have to use the predicted relevant evidences for test so we hope our classification model should have seen these wrongly predicted evidences during training."
      ],
      "metadata": {
        "id": "1n95X3of0rhN"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "tags": [],
        "id": "kFtgfiYPJgtp"
      },
      "outputs": [],
      "source": [
        "train_evidences_ids_predicted = evidence_predicts(train_claim_input, evidence_embeddings, train_sort_potential_evidences,\n",
        "                                                  evidences_ids, trans_encoder,dev_candis_num=8,retrieval_num=5)\n",
        "\n",
        "def get_negative_evidences(evidences_ids_predicted, true_evidences, evidences_id_dict):\n",
        "    \"\"\"\n",
        "    Identify negative evidences for each set of predictions based on the true evidence IDs.\n",
        "\n",
        "    Args:\n",
        "    evidences_ids_predicted (list of list of int): Predicted evidence IDs for each training example.\n",
        "    true_evidences (list of list of int): Actual evidence IDs for each training example.\n",
        "    evidences_id_dict (dict): Dictionary mapping evidence IDs to their respective indices or transformed IDs.\n",
        "\n",
        "    Returns:\n",
        "    list of list of int: List containing lists of negative evidence IDs for each training example.\n",
        "    \"\"\"\n",
        "    pred_negative_evidences = []\n",
        "    for idx, evidence_ids in enumerate(evidences_ids_predicted):\n",
        "        # Temp list to store negative evidences for the current training example\n",
        "        temp_ = []\n",
        "        # Convert the set of true evidences for current training example for faster lookup\n",
        "        true_evidence_set = set(true_evidences[idx])\n",
        "        for i in evidence_ids:\n",
        "            # Check if the mapped evidence ID is not in the set of true evidences\n",
        "            if evidences_id_dict[i] not in true_evidence_set:\n",
        "                temp_.append(evidences_id_dict[i])\n",
        "        pred_negative_evidences.append(temp_)\n",
        "    return pred_negative_evidences\n",
        "\n",
        "train_wrongly_pred_evidences = get_negative_evidences(train_evidences_ids_predicted, train_evidences, evidences_id_dict)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "tags": [],
        "id": "6PxGWEgkJgtp"
      },
      "outputs": [],
      "source": [
        "## save wrongly prediction data\n",
        "json.dump(train_wrongly_pred_evidences, open(\"pred_train_wrongly_pred_evidences.json\", \"w\"))"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 3.5 Saving retrieved evidences for dev and test"
      ],
      "metadata": {
        "id": "UtulkfQmJg8d"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "We also save the retrieved data for later claim classification.\n",
        "\n",
        "Here, we concatenate the retirieved evidences together with the claim."
      ],
      "metadata": {
        "id": "q45PguhJMogW"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "tags": [],
        "id": "Au8WWyGmJgtp"
      },
      "outputs": [],
      "source": [
        "def prepare_classification_data(claim_text_idx, evidences_ids_predicted, evidences_text_idx, evidences_id_dict, labels=None):\n",
        "    \"\"\"\n",
        "    Prepare data for classification by processing claim and evidence indices, adding special tokens, and padding.\n",
        "\n",
        "    Args:\n",
        "    claim_text_idx (list of list of int): Indices of claims.\n",
        "    evidences_ids_predicted (list of list of int): Predicted evidence IDs for each claim.\n",
        "    evidences_text_idx (dict): Dictionary mapping evidence IDs to their text indices.\n",
        "    evidences_id_dict (dict): Dictionary mapping evidence original IDs to their indices in `evidences_text_idx`.\n",
        "    labels (list of int, optional): Labels for each claim, if available (for training data).\n",
        "\n",
        "    Returns:\n",
        "    list of dict: List of dictionaries, each containing processed text and optionally a label.\n",
        "    \"\"\"\n",
        "    concatenated_claim_evidences = []\n",
        "    text_max_len = 60\n",
        "    evidence_max_len = 100\n",
        "    # limit the max length for the concatenated claim and evidences\n",
        "    # claim length + evidence length * 5 + special tokens * 6\n",
        "    # 60 + 100*5 + 6 = 566\n",
        "    all_max_len = 570\n",
        "\n",
        "    for idx, claim in enumerate(claim_text_idx):\n",
        "        cur_data = {}\n",
        "        if labels:\n",
        "            cur_data['label'] = labels[idx]\n",
        "        temp_text = [word2idx[\"<cls>\"]] + claim[:text_max_len]\n",
        "\n",
        "        # concatenate the retrieved evidences together with the claim to construct the input for claim classification\n",
        "        for predicted_evidence_id in evidences_ids_predicted[idx]:\n",
        "            temp_text.extend([word2idx[\"<sep>\"]] + evidences_text_idx[evidences_id_dict[predicted_evidence_id]][:evidence_max_len])\n",
        "        temp_text.append(word2idx[\"<sep>\"])\n",
        "\n",
        "        # Padding the sequence if necessary\n",
        "        if len(temp_text) < all_max_len:\n",
        "            temp_text.extend([word2idx[\"<pad>\"]] * (all_max_len - len(temp_text)))\n",
        "\n",
        "        cur_data['text'] = temp_text\n",
        "        concatenated_claim_evidences.append(cur_data)\n",
        "\n",
        "    return concatenated_claim_evidences"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Use the function to prepare data\n",
        "dev_concatenated_claim_evidences = prepare_classification_data(dev_claim_text_idx, dev_evidences_ids_predicted, evidences_text_idx, evidences_id_dict, dev_labels)\n",
        "test_concatenated_claim_evidences = prepare_classification_data(test_claim_text_idx, test_evidences_ids_predicted, evidences_text_idx, evidences_id_dict)\n",
        "\n",
        "# Write the processed data to JSON files\n",
        "json.dump(dev_concatenated_claim_evidences, open(\"dev_concatenated_claim_evidences.json\", \"w\"))\n",
        "json.dump(test_concatenated_claim_evidences, open(\"test_concatenated_claim_evidences.json\", \"w\"))"
      ],
      "metadata": {
        "id": "ynOTv_yjM8OZ"
      },
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mefSOe8eTmGP"
      },
      "source": [
        "## Object Oriented Programming codes here\n",
        "\n",
        "*You can use multiple code snippets. Just add more if needed*"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.10"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}