Our code are divided into 2 parts and 2 notebooks. The first one is evidence retrieval and the second one is claim classificaition.

The claim classification will need some output files generated by evidence retrieval so when you run them in colab, make sure that you put the required data files in the working directory.

Also, some of the codes for model implementation and data processing are referred from workshops.

For evidence retrieval:

The training can be quite slow under the environment of free Colab. It takes us around 3 hours to run 5 epochs as it includes validation during the training and this validation process take a lot of time to generate embeddings for all evidences.

At the end of the notebook, some json files are generated and dumped for the next part --- claim classification. We did not attach them in this zip files as we are not allowed to upload any data files and checkpoints. So when you run our notebook, you should remember to download the output files in the end and save them for the second part --- claim classification.


For claim classification:

In this part, we need some json files that we prepared from previous evidence retrieval part. Please ensure that you upload them into the right working directory in colab.
In details, they are:
1. "dev_concatenated_claim_evidences.json"
2. "test_concatenated_claim_evidences.json"
3. "pred_train_wrongly_pred_evidences.json"

For baseline Bi-LSTM model for evidence retrieval, it is just a baseline and perform poorly and we added it here because we also spent a lot of time on it and it can be seen as our efforts, too. But anyway, you can just ignore it if you have no time to see it.
